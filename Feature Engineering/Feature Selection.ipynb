{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39e0863b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import torch\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e5e9be9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>('new', 'delhi', 'andhra', 'pradesh', 'public'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>('pune', 'two', 'week', 'new', 'academic', 'ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>('guwahati', 'result', 'cbse', 'class', 'x', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>('admission', 'iims', 'say', 'kapoor', 'across...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>('mangaluru', 'mangalore', 'institute', 'techn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518330</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>('nagpur', 'akshay', 'zadgaonkar', 'child', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518331</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>('bayonetta', 'lead', 'hideki', 'kamiya', 'rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518332</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>('al', 'pacino', 'think', 'original', 'godfath...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518333</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>('late', 'episode', 'imlie', 'begin', 'aryan',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518334</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>('entire', 'world', 'lockdown', 'various', 'de...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518335 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target                                             tokens\n",
       "0       academic interests  ('new', 'delhi', 'andhra', 'pradesh', 'public'...\n",
       "1       academic interests  ('pune', 'two', 'week', 'new', 'academic', 'ye...\n",
       "2       academic interests  ('guwahati', 'result', 'cbse', 'class', 'x', '...\n",
       "3       academic interests  ('admission', 'iims', 'say', 'kapoor', 'across...\n",
       "4       academic interests  ('mangaluru', 'mangalore', 'institute', 'techn...\n",
       "...                    ...                                                ...\n",
       "518330        video gaming  ('nagpur', 'akshay', 'zadgaonkar', 'child', 'p...\n",
       "518331        video gaming  ('bayonetta', 'lead', 'hideki', 'kamiya', 'rec...\n",
       "518332        video gaming  ('al', 'pacino', 'think', 'original', 'godfath...\n",
       "518333        video gaming  ('late', 'episode', 'imlie', 'begin', 'aryan',...\n",
       "518334        video gaming  ('entire', 'world', 'lockdown', 'various', 'de...\n",
       "\n",
       "[518335 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df = pd.read_csv('C:\\\\Users\\\\asus\\\\NLP\\\\preprocessed_df.csv')\n",
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "725d5513",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"('new', 'delhi', 'andhra', 'pradesh', 'public', 'service', 'commission', 'appsc', 'release', 'appsc', 'group', 'notification', 'official', 'website', 'december', 'per', 'notification', 'vacancy', 'fill', 'examination', 'interested', 'eligible', 'candidate', 'apply', 'appsc', 'group', 'vacancy', 'january', 'january', 'official', 'website', 'ap', 'psc', 'conduct', 'screeningpreliminary', 'test', 'may', 'main', 'exam', 'successful', 'candidate', 'would', 'conduct', 'july', 'appsc', 'group', 'important', 'date', 'event', 'date', 'opening', 'date', 'application', 'jan', 'closing', 'date', 'application', 'jan', 'appsc', 'group', 'vacancy', 'detail', 'type', 'carry', 'forward', 'executive', 'post', 'nonexecutive', 'post', 'type', 'fresh', 'post', 'executive', 'post', 'nonexecutive', 'post', 'total', 'educational', 'qualificationgraduation', 'degree', 'discipline', 'recognize', 'university', 'institute', 'age', 'limit', 'july', 'minimum', 'yearsmaximum', 'year', 'feesapplication', 'fee', 'rs', 'examination', 'fee', 'rs', 'examination', 'fee', 'candidate', 'belong', 'reserved', 'category', 'like', 'sc', 'st', 'bc', 'ph', 'exservicemen', 'etc', 'appsc', 'conduct', 'recruitment', 'drive', 'fill', 'vacancy', 'group', 'category', 'group', 'post', 'include', 'asst', 'commercial', 'tax', 'officer', 'ap', 'commercial', 'tax', 'subordinate', 'service', 'deputy', 'tahsildar', 'ap', 'revenue', 'subordinate', 'service', 'senior', 'auditor', 'ap', 'state', 'audit', 'subordinate', 'service', 'municipal', 'commissioner', 'gradeiii', 'ap', 'municipal', 'commissioner', 'subordinate', 'service', 'etc')\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.iloc[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8aa94d67",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "preprocessed_df.tokens = preprocessed_df.tokens.apply(ast.literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cee841e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('new',\n",
       " 'delhi',\n",
       " 'andhra',\n",
       " 'pradesh',\n",
       " 'public',\n",
       " 'service',\n",
       " 'commission',\n",
       " 'appsc',\n",
       " 'release',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'notification',\n",
       " 'official',\n",
       " 'website',\n",
       " 'december',\n",
       " 'per',\n",
       " 'notification',\n",
       " 'vacancy',\n",
       " 'fill',\n",
       " 'examination',\n",
       " 'interested',\n",
       " 'eligible',\n",
       " 'candidate',\n",
       " 'apply',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'vacancy',\n",
       " 'january',\n",
       " 'january',\n",
       " 'official',\n",
       " 'website',\n",
       " 'ap',\n",
       " 'psc',\n",
       " 'conduct',\n",
       " 'screeningpreliminary',\n",
       " 'test',\n",
       " 'may',\n",
       " 'main',\n",
       " 'exam',\n",
       " 'successful',\n",
       " 'candidate',\n",
       " 'would',\n",
       " 'conduct',\n",
       " 'july',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'important',\n",
       " 'date',\n",
       " 'event',\n",
       " 'date',\n",
       " 'opening',\n",
       " 'date',\n",
       " 'application',\n",
       " 'jan',\n",
       " 'closing',\n",
       " 'date',\n",
       " 'application',\n",
       " 'jan',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'vacancy',\n",
       " 'detail',\n",
       " 'type',\n",
       " 'carry',\n",
       " 'forward',\n",
       " 'executive',\n",
       " 'post',\n",
       " 'nonexecutive',\n",
       " 'post',\n",
       " 'type',\n",
       " 'fresh',\n",
       " 'post',\n",
       " 'executive',\n",
       " 'post',\n",
       " 'nonexecutive',\n",
       " 'post',\n",
       " 'total',\n",
       " 'educational',\n",
       " 'qualificationgraduation',\n",
       " 'degree',\n",
       " 'discipline',\n",
       " 'recognize',\n",
       " 'university',\n",
       " 'institute',\n",
       " 'age',\n",
       " 'limit',\n",
       " 'july',\n",
       " 'minimum',\n",
       " 'yearsmaximum',\n",
       " 'year',\n",
       " 'feesapplication',\n",
       " 'fee',\n",
       " 'rs',\n",
       " 'examination',\n",
       " 'fee',\n",
       " 'rs',\n",
       " 'examination',\n",
       " 'fee',\n",
       " 'candidate',\n",
       " 'belong',\n",
       " 'reserved',\n",
       " 'category',\n",
       " 'like',\n",
       " 'sc',\n",
       " 'st',\n",
       " 'bc',\n",
       " 'ph',\n",
       " 'exservicemen',\n",
       " 'etc',\n",
       " 'appsc',\n",
       " 'conduct',\n",
       " 'recruitment',\n",
       " 'drive',\n",
       " 'fill',\n",
       " 'vacancy',\n",
       " 'group',\n",
       " 'category',\n",
       " 'group',\n",
       " 'post',\n",
       " 'include',\n",
       " 'asst',\n",
       " 'commercial',\n",
       " 'tax',\n",
       " 'officer',\n",
       " 'ap',\n",
       " 'commercial',\n",
       " 'tax',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'deputy',\n",
       " 'tahsildar',\n",
       " 'ap',\n",
       " 'revenue',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'senior',\n",
       " 'auditor',\n",
       " 'ap',\n",
       " 'state',\n",
       " 'audit',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'municipal',\n",
       " 'commissioner',\n",
       " 'gradeiii',\n",
       " 'ap',\n",
       " 'municipal',\n",
       " 'commissioner',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'etc')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.iloc[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6e6a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_df['Count'] = preprocessed_df.tokens.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c32daef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(new, delhi, andhra, pradesh, public, service,...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(pune, two, week, new, academic, year, begin, ...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(guwahati, result, cbse, class, x, exam, annou...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(admission, iims, say, kapoor, across, iims, s...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(mangaluru, mangalore, institute, technology, ...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518330</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(nagpur, akshay, zadgaonkar, child, prodigy, c...</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518331</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(bayonetta, lead, hideki, kamiya, reckons, lat...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518332</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(al, pacino, think, original, godfather, well,...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518333</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(late, episode, imlie, begin, aryan, receive, ...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518334</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(entire, world, lockdown, various, degree, peo...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>518335 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target                                             tokens  \\\n",
       "0       academic interests  (new, delhi, andhra, pradesh, public, service,...   \n",
       "1       academic interests  (pune, two, week, new, academic, year, begin, ...   \n",
       "2       academic interests  (guwahati, result, cbse, class, x, exam, annou...   \n",
       "3       academic interests  (admission, iims, say, kapoor, across, iims, s...   \n",
       "4       academic interests  (mangaluru, mangalore, institute, technology, ...   \n",
       "...                    ...                                                ...   \n",
       "518330        video gaming  (nagpur, akshay, zadgaonkar, child, prodigy, c...   \n",
       "518331        video gaming  (bayonetta, lead, hideki, kamiya, reckons, lat...   \n",
       "518332        video gaming  (al, pacino, think, original, godfather, well,...   \n",
       "518333        video gaming  (late, episode, imlie, begin, aryan, receive, ...   \n",
       "518334        video gaming  (entire, world, lockdown, various, degree, peo...   \n",
       "\n",
       "        Count  \n",
       "0         151  \n",
       "1         269  \n",
       "2         261  \n",
       "3          56  \n",
       "4         203  \n",
       "...       ...  \n",
       "518330    291  \n",
       "518331    176  \n",
       "518332    147  \n",
       "518333    130  \n",
       "518334    115  \n",
       "\n",
       "[518335 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8de97e04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    518335.000000\n",
       "mean        179.827382\n",
       "std          80.234937\n",
       "min           0.000000\n",
       "25%         109.000000\n",
       "50%         173.000000\n",
       "75%         250.000000\n",
       "max         500.000000\n",
       "Name: Count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df.Count.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79962e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2957</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(jaipur, timetable, rajasthan, grade, teacher,...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(bth, hjpi, hjpii, mfp, nke, spji, spjii, spji...</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7338</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(director, civil, defence, cooperative, societ...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10152</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(lie, vacantnone, position, vacant, qualified,...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11146</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(chhatra, marg, shambhavi, subhashini, tell, t...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514232</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(analyst, look, back, grateful, shivlal, yadav...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515827</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(also, give, golfer, fresh, perspective, life,...</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516891</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(go, help, go, favour, even, rubina, authorita...</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518009</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(two, day, definitely, watch, day, afternot, a...</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518039</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(get, loop, zip, accuracy, back, important, sp...</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>837 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target                                             tokens  \\\n",
       "2957    academic interests  (jaipur, timetable, rajasthan, grade, teacher,...   \n",
       "3585    academic interests  (bth, hjpi, hjpii, mfp, nke, spji, spjii, spji...   \n",
       "7338    academic interests  (director, civil, defence, cooperative, societ...   \n",
       "10152   academic interests  (lie, vacantnone, position, vacant, qualified,...   \n",
       "11146   academic interests  (chhatra, marg, shambhavi, subhashini, tell, t...   \n",
       "...                    ...                                                ...   \n",
       "514232        video gaming  (analyst, look, back, grateful, shivlal, yadav...   \n",
       "515827        video gaming  (also, give, golfer, fresh, perspective, life,...   \n",
       "516891        video gaming  (go, help, go, favour, even, rubina, authorita...   \n",
       "518009        video gaming  (two, day, definitely, watch, day, afternot, a...   \n",
       "518039        video gaming  (get, loop, zip, accuracy, back, important, sp...   \n",
       "\n",
       "        Count  \n",
       "2957       49  \n",
       "3585       36  \n",
       "7338       46  \n",
       "10152      48  \n",
       "11146      48  \n",
       "...       ...  \n",
       "514232     48  \n",
       "515827     46  \n",
       "516891     47  \n",
       "518009     48  \n",
       "518039     49  \n",
       "\n",
       "[837 rows x 3 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_df[preprocessed_df.Count < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8ac1203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(new, delhi, andhra, pradesh, public, service,...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(pune, two, week, new, academic, year, begin, ...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(guwahati, result, cbse, class, x, exam, annou...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(admission, iims, say, kapoor, across, iims, s...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>(mangaluru, mangalore, institute, technology, ...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518330</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(nagpur, akshay, zadgaonkar, child, prodigy, c...</td>\n",
       "      <td>291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518331</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(bayonetta, lead, hideki, kamiya, reckons, lat...</td>\n",
       "      <td>176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518332</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(al, pacino, think, original, godfather, well,...</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518333</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(late, episode, imlie, begin, aryan, receive, ...</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518334</th>\n",
       "      <td>video gaming</td>\n",
       "      <td>(entire, world, lockdown, various, degree, peo...</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>517498 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    target                                             tokens  \\\n",
       "0       academic interests  (new, delhi, andhra, pradesh, public, service,...   \n",
       "1       academic interests  (pune, two, week, new, academic, year, begin, ...   \n",
       "2       academic interests  (guwahati, result, cbse, class, x, exam, annou...   \n",
       "3       academic interests  (admission, iims, say, kapoor, across, iims, s...   \n",
       "4       academic interests  (mangaluru, mangalore, institute, technology, ...   \n",
       "...                    ...                                                ...   \n",
       "518330        video gaming  (nagpur, akshay, zadgaonkar, child, prodigy, c...   \n",
       "518331        video gaming  (bayonetta, lead, hideki, kamiya, reckons, lat...   \n",
       "518332        video gaming  (al, pacino, think, original, godfather, well,...   \n",
       "518333        video gaming  (late, episode, imlie, begin, aryan, receive, ...   \n",
       "518334        video gaming  (entire, world, lockdown, various, degree, peo...   \n",
       "\n",
       "        Count  \n",
       "0         151  \n",
       "1         269  \n",
       "2         261  \n",
       "3          56  \n",
       "4         203  \n",
       "...       ...  \n",
       "518330    291  \n",
       "518331    176  \n",
       "518332    147  \n",
       "518333    130  \n",
       "518334    115  \n",
       "\n",
       "[517498 rows x 3 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = preprocessed_df[preprocessed_df.Count >= 50]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a281d349",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_6984\\3196849200.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokens'] = df['tokens'].apply(list)\n"
     ]
    }
   ],
   "source": [
    "df['tokens'] = df['tokens'].apply(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80850f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['new',\n",
       " 'delhi',\n",
       " 'andhra',\n",
       " 'pradesh',\n",
       " 'public',\n",
       " 'service',\n",
       " 'commission',\n",
       " 'appsc',\n",
       " 'release',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'notification',\n",
       " 'official',\n",
       " 'website',\n",
       " 'december',\n",
       " 'per',\n",
       " 'notification',\n",
       " 'vacancy',\n",
       " 'fill',\n",
       " 'examination',\n",
       " 'interested',\n",
       " 'eligible',\n",
       " 'candidate',\n",
       " 'apply',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'vacancy',\n",
       " 'january',\n",
       " 'january',\n",
       " 'official',\n",
       " 'website',\n",
       " 'ap',\n",
       " 'psc',\n",
       " 'conduct',\n",
       " 'screeningpreliminary',\n",
       " 'test',\n",
       " 'may',\n",
       " 'main',\n",
       " 'exam',\n",
       " 'successful',\n",
       " 'candidate',\n",
       " 'would',\n",
       " 'conduct',\n",
       " 'july',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'important',\n",
       " 'date',\n",
       " 'event',\n",
       " 'date',\n",
       " 'opening',\n",
       " 'date',\n",
       " 'application',\n",
       " 'jan',\n",
       " 'closing',\n",
       " 'date',\n",
       " 'application',\n",
       " 'jan',\n",
       " 'appsc',\n",
       " 'group',\n",
       " 'vacancy',\n",
       " 'detail',\n",
       " 'type',\n",
       " 'carry',\n",
       " 'forward',\n",
       " 'executive',\n",
       " 'post',\n",
       " 'nonexecutive',\n",
       " 'post',\n",
       " 'type',\n",
       " 'fresh',\n",
       " 'post',\n",
       " 'executive',\n",
       " 'post',\n",
       " 'nonexecutive',\n",
       " 'post',\n",
       " 'total',\n",
       " 'educational',\n",
       " 'qualificationgraduation',\n",
       " 'degree',\n",
       " 'discipline',\n",
       " 'recognize',\n",
       " 'university',\n",
       " 'institute',\n",
       " 'age',\n",
       " 'limit',\n",
       " 'july',\n",
       " 'minimum',\n",
       " 'yearsmaximum',\n",
       " 'year',\n",
       " 'feesapplication',\n",
       " 'fee',\n",
       " 'rs',\n",
       " 'examination',\n",
       " 'fee',\n",
       " 'rs',\n",
       " 'examination',\n",
       " 'fee',\n",
       " 'candidate',\n",
       " 'belong',\n",
       " 'reserved',\n",
       " 'category',\n",
       " 'like',\n",
       " 'sc',\n",
       " 'st',\n",
       " 'bc',\n",
       " 'ph',\n",
       " 'exservicemen',\n",
       " 'etc',\n",
       " 'appsc',\n",
       " 'conduct',\n",
       " 'recruitment',\n",
       " 'drive',\n",
       " 'fill',\n",
       " 'vacancy',\n",
       " 'group',\n",
       " 'category',\n",
       " 'group',\n",
       " 'post',\n",
       " 'include',\n",
       " 'asst',\n",
       " 'commercial',\n",
       " 'tax',\n",
       " 'officer',\n",
       " 'ap',\n",
       " 'commercial',\n",
       " 'tax',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'deputy',\n",
       " 'tahsildar',\n",
       " 'ap',\n",
       " 'revenue',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'senior',\n",
       " 'auditor',\n",
       " 'ap',\n",
       " 'state',\n",
       " 'audit',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'municipal',\n",
       " 'commissioner',\n",
       " 'gradeiii',\n",
       " 'ap',\n",
       " 'municipal',\n",
       " 'commissioner',\n",
       " 'subordinate',\n",
       " 'service',\n",
       " 'etc']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0].tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f820bcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    517498.000000\n",
       "mean        180.047191\n",
       "std          80.112442\n",
       "min          50.000000\n",
       "25%         109.000000\n",
       "50%         174.000000\n",
       "75%         250.000000\n",
       "max         500.000000\n",
       "Name: Count, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Count.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127279ba",
   "metadata": {},
   "source": [
    "## Sampling code for generating word embeddings using 'bert-base-uncased' and 'TinyBERT' model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c1dd1c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[new, delhi, andhra, pradesh, public, service,...</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[pune, two, week, new, academic, year, begin, ...</td>\n",
       "      <td>269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[guwahati, result, cbse, class, x, exam, annou...</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[admission, iims, say, kapoor, across, iims, s...</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[mangaluru, mangalore, institute, technology, ...</td>\n",
       "      <td>203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[chennai, many, undergraduate, student, indian...</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[patna, fake, real, report, commencement, biha...</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[bhopal, base, aisect, partnered, national, sk...</td>\n",
       "      <td>210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[mumbai, iitbombay, heritage, foundation, anno...</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[thiruvananthapuram, kerala, state, high, seco...</td>\n",
       "      <td>207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                target                                             tokens  \\\n",
       "0   academic interests  [new, delhi, andhra, pradesh, public, service,...   \n",
       "1   academic interests  [pune, two, week, new, academic, year, begin, ...   \n",
       "2   academic interests  [guwahati, result, cbse, class, x, exam, annou...   \n",
       "3   academic interests  [admission, iims, say, kapoor, across, iims, s...   \n",
       "4   academic interests  [mangaluru, mangalore, institute, technology, ...   \n",
       "..                 ...                                                ...   \n",
       "95  academic interests  [chennai, many, undergraduate, student, indian...   \n",
       "96  academic interests  [patna, fake, real, report, commencement, biha...   \n",
       "97  academic interests  [bhopal, base, aisect, partnered, national, sk...   \n",
       "98  academic interests  [mumbai, iitbombay, heritage, foundation, anno...   \n",
       "99  academic interests  [thiruvananthapuram, kerala, state, high, seco...   \n",
       "\n",
       "    Count  \n",
       "0     151  \n",
       "1     269  \n",
       "2     261  \n",
       "3      56  \n",
       "4     203  \n",
       "..    ...  \n",
       "95    195  \n",
       "96    237  \n",
       "97    210  \n",
       "98    112  \n",
       "99    207  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.head(100)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "19d68882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f35e78b3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "\n",
    "model_name = \"prajjwal1/bert-tiny\"\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(model_name)\n",
    "model1 = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08053055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(token):\n",
    "    token = ' '.join(token)\n",
    "    token_ids = tokenizer.encode(token, add_special_tokens=True, max_length=512, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(token_ids)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    return token_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f37ebd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings_tiny(token):\n",
    "    token = ' '.join(token)\n",
    "    token_ids = tokenizer1.encode(token, add_special_tokens=True, max_length=500, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model1(token_ids)\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    return token_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "535b8309",
   "metadata": {},
   "source": [
    "### Using 'bert-base-uncased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35e2f0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample['embeddings'] = sample['tokens'].apply(generate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3579926e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.10234293,  0.2681388 ,  0.3079377 , ..., -0.24406022,\n",
       "          0.22923225,  0.25526968],\n",
       "        [ 0.24037577, -0.6226484 ,  0.04673899, ...,  0.42858577,\n",
       "          1.0363635 , -1.3937992 ],\n",
       "        [-0.41201788,  0.13874632, -0.1011709 , ..., -0.7874209 ,\n",
       "         -0.54978263, -0.18123682],\n",
       "        ...,\n",
       "        [ 0.2418448 ,  0.20564106,  0.17275977, ..., -0.28972432,\n",
       "          0.02567784, -0.35089576],\n",
       "        [-0.05552824, -0.5804872 ,  0.36592537, ...,  0.34253207,\n",
       "         -0.29407305, -0.5665064 ],\n",
       "        [ 0.8853692 ,  0.23278204,  0.2158145 , ...,  0.5613418 ,\n",
       "         -0.01800169, -0.00208989]]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.iloc[0].embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "19901e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186, 768)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.iloc[0].embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ee253",
   "metadata": {},
   "source": [
    "### Using 'TinyBert'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fec8c37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sample.iloc[44].tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dea72d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "C:\\Users\\asus\\AppData\\Local\\Temp\\ipykernel_11596\\904850502.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample['embeddings1'] = sample['tokens'].apply(generate_embeddings_tiny)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>tokens</th>\n",
       "      <th>Count</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>embeddings1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[new, delhi, andhra, pradesh, public, service,...</td>\n",
       "      <td>151</td>\n",
       "      <td>[[[-0.102342926, 0.2681388, 0.3079377, -0.0155...</td>\n",
       "      <td>[[[-0.24230754, 0.6758959, -3.0359886, 0.14046...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[pune, two, week, new, academic, year, begin, ...</td>\n",
       "      <td>269</td>\n",
       "      <td>[[[0.017289966, 0.053193845, 0.004283134, -0.0...</td>\n",
       "      <td>[[[-0.37797007, 0.33381104, -3.0789416, -0.120...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[guwahati, result, cbse, class, x, exam, annou...</td>\n",
       "      <td>261</td>\n",
       "      <td>[[[-0.17666939, 0.22534966, 0.16726117, 0.0804...</td>\n",
       "      <td>[[[-0.64431006, 0.20074141, -3.523524, 0.31455...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[admission, iims, say, kapoor, across, iims, s...</td>\n",
       "      <td>56</td>\n",
       "      <td>[[[-0.47793072, -0.22164372, 0.45299107, -0.04...</td>\n",
       "      <td>[[[-1.1897714, -0.17914984, -4.576548, -0.4710...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[mangaluru, mangalore, institute, technology, ...</td>\n",
       "      <td>203</td>\n",
       "      <td>[[[-0.39018634, 0.06787005, 0.15971534, 0.1613...</td>\n",
       "      <td>[[[-0.16192678, 0.8034336, -3.237337, 0.577428...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[chennai, many, undergraduate, student, indian...</td>\n",
       "      <td>195</td>\n",
       "      <td>[[[-0.012010816, 0.10340781, 0.22483017, -0.05...</td>\n",
       "      <td>[[[-0.44404083, -0.23386297, -3.1620395, 0.101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[patna, fake, real, report, commencement, biha...</td>\n",
       "      <td>237</td>\n",
       "      <td>[[[-0.114917256, 0.10928891, 0.14564778, 0.062...</td>\n",
       "      <td>[[[-0.54735345, 0.39602095, -3.0180976, 0.1163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[bhopal, base, aisect, partnered, national, sk...</td>\n",
       "      <td>210</td>\n",
       "      <td>[[[-0.13440078, 0.23854807, 0.25590187, 0.0512...</td>\n",
       "      <td>[[[0.4377316, 0.90364367, -3.3147984, 0.555523...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[mumbai, iitbombay, heritage, foundation, anno...</td>\n",
       "      <td>112</td>\n",
       "      <td>[[[-0.05118098, -0.22517866, 0.17694403, -0.03...</td>\n",
       "      <td>[[[0.05541656, 0.7737858, -3.2258377, -0.06067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>academic interests</td>\n",
       "      <td>[thiruvananthapuram, kerala, state, high, seco...</td>\n",
       "      <td>207</td>\n",
       "      <td>[[[-0.14194185, -0.11891071, 0.47339374, 0.033...</td>\n",
       "      <td>[[[-0.99853754, -0.043362778, -3.134083, 0.081...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                target                                             tokens  \\\n",
       "0   academic interests  [new, delhi, andhra, pradesh, public, service,...   \n",
       "1   academic interests  [pune, two, week, new, academic, year, begin, ...   \n",
       "2   academic interests  [guwahati, result, cbse, class, x, exam, annou...   \n",
       "3   academic interests  [admission, iims, say, kapoor, across, iims, s...   \n",
       "4   academic interests  [mangaluru, mangalore, institute, technology, ...   \n",
       "..                 ...                                                ...   \n",
       "95  academic interests  [chennai, many, undergraduate, student, indian...   \n",
       "96  academic interests  [patna, fake, real, report, commencement, biha...   \n",
       "97  academic interests  [bhopal, base, aisect, partnered, national, sk...   \n",
       "98  academic interests  [mumbai, iitbombay, heritage, foundation, anno...   \n",
       "99  academic interests  [thiruvananthapuram, kerala, state, high, seco...   \n",
       "\n",
       "    Count                                         embeddings  \\\n",
       "0     151  [[[-0.102342926, 0.2681388, 0.3079377, -0.0155...   \n",
       "1     269  [[[0.017289966, 0.053193845, 0.004283134, -0.0...   \n",
       "2     261  [[[-0.17666939, 0.22534966, 0.16726117, 0.0804...   \n",
       "3      56  [[[-0.47793072, -0.22164372, 0.45299107, -0.04...   \n",
       "4     203  [[[-0.39018634, 0.06787005, 0.15971534, 0.1613...   \n",
       "..    ...                                                ...   \n",
       "95    195  [[[-0.012010816, 0.10340781, 0.22483017, -0.05...   \n",
       "96    237  [[[-0.114917256, 0.10928891, 0.14564778, 0.062...   \n",
       "97    210  [[[-0.13440078, 0.23854807, 0.25590187, 0.0512...   \n",
       "98    112  [[[-0.05118098, -0.22517866, 0.17694403, -0.03...   \n",
       "99    207  [[[-0.14194185, -0.11891071, 0.47339374, 0.033...   \n",
       "\n",
       "                                          embeddings1  \n",
       "0   [[[-0.24230754, 0.6758959, -3.0359886, 0.14046...  \n",
       "1   [[[-0.37797007, 0.33381104, -3.0789416, -0.120...  \n",
       "2   [[[-0.64431006, 0.20074141, -3.523524, 0.31455...  \n",
       "3   [[[-1.1897714, -0.17914984, -4.576548, -0.4710...  \n",
       "4   [[[-0.16192678, 0.8034336, -3.237337, 0.577428...  \n",
       "..                                                ...  \n",
       "95  [[[-0.44404083, -0.23386297, -3.1620395, 0.101...  \n",
       "96  [[[-0.54735345, 0.39602095, -3.0180976, 0.1163...  \n",
       "97  [[[0.4377316, 0.90364367, -3.3147984, 0.555523...  \n",
       "98  [[[0.05541656, 0.7737858, -3.2258377, -0.06067...  \n",
       "99  [[[-0.99853754, -0.043362778, -3.134083, 0.081...  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample['embeddings1'] = sample['tokens'].apply(generate_embeddings_tiny)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13907942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.24230754,  0.6758959 , -3.0359886 , ..., -2.4825253 ,\n",
       "         -0.54429233, -0.02109066],\n",
       "        [ 0.06733874,  0.9371697 , -0.7385615 , ..., -0.9727076 ,\n",
       "         -2.816767  ,  2.0776396 ],\n",
       "        [ 0.07239322,  0.36698726, -1.4181027 , ..., -2.691685  ,\n",
       "         -1.9709718 ,  1.3073338 ],\n",
       "        ...,\n",
       "        [ 0.25061396,  1.4571034 , -0.3956341 , ..., -2.6564639 ,\n",
       "          0.24109644,  0.7127943 ],\n",
       "        [-1.1011935 ,  0.77729183, -0.3153417 , ..., -3.9850006 ,\n",
       "         -0.70202434, -0.07632882],\n",
       "        [-0.04574512,  1.0815307 , -0.03484747, ..., -1.1708034 ,\n",
       "         -0.554181  ,  0.08455859]]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.iloc[0].embeddings1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "17f2bc69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 186, 128)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.iloc[0].embeddings1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6531333b",
   "metadata": {},
   "source": [
    "## Dividing df categories-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f03ec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def category_dataframes(df):\n",
    "   \n",
    "    unique_categories = df['target'].unique()\n",
    "    \n",
    "    category_dataframes = {}\n",
    "    \n",
    "    for category in unique_categories:\n",
    "        filtered_df = df[df['target'] == category].copy()\n",
    "        filtered_df.reset_index(drop=True, inplace=True)\n",
    "        category_dataframes[category] = filtered_df\n",
    "\n",
    "    return category_dataframes\n",
    "\n",
    "category_dfs = category_dataframes(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bda7207",
   "metadata": {},
   "source": [
    "## Generating word embeddings using TinyBERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16c1e534",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['academic interests', 'arts and culture', 'automotives',\n",
       "       'books and literature', 'business and finance', 'careers',\n",
       "       'family and relationships', 'food and drinks', 'health',\n",
       "       'healthy living', 'hobbies and interests', 'home and garden',\n",
       "       'movies', 'music and audio', 'news and politics',\n",
       "       'personal finance', 'pets',\n",
       "       'pharmaceuticals, conditions, and symptoms', 'real estate',\n",
       "       'shopping', 'sports', 'style and fashion',\n",
       "       'technology and computing', 'television', 'travel', 'video gaming'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798a3731",
   "metadata": {},
   "source": [
    "### Academic Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f9531a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[new, delhi, andhra, pradesh, public, service,...</td>\n",
       "      <td>[[[-0.24230754, 0.6758959, -3.0359886, 0.14046...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pune, two, week, new, academic, year, begin, ...</td>\n",
       "      <td>[[[-0.37797007, 0.33381104, -3.0789416, -0.120...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[guwahati, result, cbse, class, x, exam, annou...</td>\n",
       "      <td>[[[-0.64431006, 0.20074141, -3.523524, 0.31455...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[admission, iims, say, kapoor, across, iims, s...</td>\n",
       "      <td>[[[-1.1897714, -0.17914984, -4.576548, -0.4710...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mangaluru, mangalore, institute, technology, ...</td>\n",
       "      <td>[[[-0.16192678, 0.8034336, -3.237337, 0.577428...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19979</th>\n",
       "      <td>[odisha, th, result, board, secondary, educati...</td>\n",
       "      <td>[[[-0.7888885, 0.7269752, -3.3675919, -0.01822...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19980</th>\n",
       "      <td>[fund, federal, government, programme, urge, b...</td>\n",
       "      <td>[[[-0.9928848, 0.5346526, -3.8557582, 0.059418...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19981</th>\n",
       "      <td>[pune, student, appear, secondary, school, cer...</td>\n",
       "      <td>[[[-0.8052787, 0.2641247, -3.278021, -0.630721...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19982</th>\n",
       "      <td>[new, delhi, past, two, day, see, surge, onlin...</td>\n",
       "      <td>[[[-0.5997653, 0.19085337, -3.123851, 0.028076...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19983</th>\n",
       "      <td>[telangana, state, public, service, commission...</td>\n",
       "      <td>[[[-0.6419734, 0.79481804, -3.0367298, -0.1388...</td>\n",
       "      <td>academic interests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19984 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [new, delhi, andhra, pradesh, public, service,...   \n",
       "1      [pune, two, week, new, academic, year, begin, ...   \n",
       "2      [guwahati, result, cbse, class, x, exam, annou...   \n",
       "3      [admission, iims, say, kapoor, across, iims, s...   \n",
       "4      [mangaluru, mangalore, institute, technology, ...   \n",
       "...                                                  ...   \n",
       "19979  [odisha, th, result, board, secondary, educati...   \n",
       "19980  [fund, federal, government, programme, urge, b...   \n",
       "19981  [pune, student, appear, secondary, school, cer...   \n",
       "19982  [new, delhi, past, two, day, see, surge, onlin...   \n",
       "19983  [telangana, state, public, service, commission...   \n",
       "\n",
       "                                              embeddings              target  \n",
       "0      [[[-0.24230754, 0.6758959, -3.0359886, 0.14046...  academic interests  \n",
       "1      [[[-0.37797007, 0.33381104, -3.0789416, -0.120...  academic interests  \n",
       "2      [[[-0.64431006, 0.20074141, -3.523524, 0.31455...  academic interests  \n",
       "3      [[[-1.1897714, -0.17914984, -4.576548, -0.4710...  academic interests  \n",
       "4      [[[-0.16192678, 0.8034336, -3.237337, 0.577428...  academic interests  \n",
       "...                                                  ...                 ...  \n",
       "19979  [[[-0.7888885, 0.7269752, -3.3675919, -0.01822...  academic interests  \n",
       "19980  [[[-0.9928848, 0.5346526, -3.8557582, 0.059418...  academic interests  \n",
       "19981  [[[-0.8052787, 0.2641247, -3.278021, -0.630721...  academic interests  \n",
       "19982  [[[-0.5997653, 0.19085337, -3.123851, 0.028076...  academic interests  \n",
       "19983  [[[-0.6419734, 0.79481804, -3.0367298, -0.1388...  academic interests  \n",
       "\n",
       "[19984 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em1 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em1['embeddings'] = category_dfs['academic interests'].tokens.apply(generate_embeddings_tiny)\n",
    "em1['tokens'] = category_dfs['academic interests'].tokens\n",
    "em1['target'] = 'academic interests'\n",
    "em1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c6b7016b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.24230754,  0.6758959 , -3.0359886 , ..., -2.4825253 ,\n",
       "         -0.54429233, -0.02109066],\n",
       "        [ 0.06733874,  0.9371697 , -0.7385615 , ..., -0.9727076 ,\n",
       "         -2.816767  ,  2.0776396 ],\n",
       "        [ 0.07239322,  0.36698726, -1.4181027 , ..., -2.691685  ,\n",
       "         -1.9709718 ,  1.3073338 ],\n",
       "        ...,\n",
       "        [ 0.25061396,  1.4571034 , -0.3956341 , ..., -2.6564639 ,\n",
       "          0.24109644,  0.7127943 ],\n",
       "        [-1.1011935 ,  0.77729183, -0.3153417 , ..., -3.9850006 ,\n",
       "         -0.70202434, -0.07632882],\n",
       "        [-0.04574512,  1.0815307 , -0.03484747, ..., -1.1708034 ,\n",
       "         -0.554181  ,  0.08455859]]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em1.iloc[0].embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ce13c807",
   "metadata": {},
   "outputs": [],
   "source": [
    "em1.to_pickle('em1.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aebdfe5",
   "metadata": {},
   "source": [
    "### Arts and Culture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60f3b60a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[japan, foundation, travel, exhibition, title,...</td>\n",
       "      <td>[[[-0.38452643, 0.16384767, -3.7767115, 0.5209...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[first, come, kolkata, school, believe, city, ...</td>\n",
       "      <td>[[[-0.884976, -1.4084904, -3.1018827, 0.319805...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[filmmaker, vivek, agnihotri, saturday, tell, ...</td>\n",
       "      <td>[[[0.41287118, -1.2298089, -3.017241, 0.024169...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[mangaluru, mangalore, university, award, phd,...</td>\n",
       "      <td>[[[-0.65316397, -0.34860578, -2.9371707, -0.52...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[graphic, novelist, abhijeet, kini, give, read...</td>\n",
       "      <td>[[[-0.32366264, -0.4596825, -2.8497071, 0.1776...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>[chandigarh, theme, tribe, india, fourth, edit...</td>\n",
       "      <td>[[[0.03243974, 0.18198806, -2.3291063, 0.39486...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19929</th>\n",
       "      <td>[pune, air, force, station, afs, lohegaon, dis...</td>\n",
       "      <td>[[[0.42408565, 0.32918972, -3.3979354, 0.32422...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>[filmmaker, mahesh, bhatt, confirm, adult, fil...</td>\n",
       "      <td>[[[0.9870384, -1.0998493, -3.164177, 0.1130499...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19931</th>\n",
       "      <td>[hour, half, long, wait, gate, finally, open, ...</td>\n",
       "      <td>[[[0.20119381, -0.20482069, -2.6506596, 0.3866...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19932</th>\n",
       "      <td>[abu, dhabi, cosmopolitan, business, city, get...</td>\n",
       "      <td>[[[0.032289132, -0.65612847, -2.5873742, 0.592...</td>\n",
       "      <td>arts and culture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19933 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [japan, foundation, travel, exhibition, title,...   \n",
       "1      [first, come, kolkata, school, believe, city, ...   \n",
       "2      [filmmaker, vivek, agnihotri, saturday, tell, ...   \n",
       "3      [mangaluru, mangalore, university, award, phd,...   \n",
       "4      [graphic, novelist, abhijeet, kini, give, read...   \n",
       "...                                                  ...   \n",
       "19928  [chandigarh, theme, tribe, india, fourth, edit...   \n",
       "19929  [pune, air, force, station, afs, lohegaon, dis...   \n",
       "19930  [filmmaker, mahesh, bhatt, confirm, adult, fil...   \n",
       "19931  [hour, half, long, wait, gate, finally, open, ...   \n",
       "19932  [abu, dhabi, cosmopolitan, business, city, get...   \n",
       "\n",
       "                                              embeddings            target  \n",
       "0      [[[-0.38452643, 0.16384767, -3.7767115, 0.5209...  arts and culture  \n",
       "1      [[[-0.884976, -1.4084904, -3.1018827, 0.319805...  arts and culture  \n",
       "2      [[[0.41287118, -1.2298089, -3.017241, 0.024169...  arts and culture  \n",
       "3      [[[-0.65316397, -0.34860578, -2.9371707, -0.52...  arts and culture  \n",
       "4      [[[-0.32366264, -0.4596825, -2.8497071, 0.1776...  arts and culture  \n",
       "...                                                  ...               ...  \n",
       "19928  [[[0.03243974, 0.18198806, -2.3291063, 0.39486...  arts and culture  \n",
       "19929  [[[0.42408565, 0.32918972, -3.3979354, 0.32422...  arts and culture  \n",
       "19930  [[[0.9870384, -1.0998493, -3.164177, 0.1130499...  arts and culture  \n",
       "19931  [[[0.20119381, -0.20482069, -2.6506596, 0.3866...  arts and culture  \n",
       "19932  [[[0.032289132, -0.65612847, -2.5873742, 0.592...  arts and culture  \n",
       "\n",
       "[19933 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em2 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em2['embeddings'] = category_dfs['arts and culture'].tokens.apply(generate_embeddings_tiny)\n",
    "em2['tokens'] = category_dfs['arts and culture'].tokens\n",
    "em2['target'] = 'arts and culture'\n",
    "em2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3902d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "em2.to_pickle('em2.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6807b19",
   "metadata": {},
   "source": [
    "### Automotives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ca14d8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[november, pv, sale, november, top, pv, sale, ...</td>\n",
       "      <td>[[[-0.17716253, 0.20208414, -3.1956387, -0.016...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[visteon, ecarx, jointly, support, lead, inveh...</td>\n",
       "      <td>[[[0.47310433, 0.110844806, -2.8415854, 0.2583...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[well, ajay, singh, run, state, bank, india, k...</td>\n",
       "      <td>[[[-0.5193571, -0.086186826, -2.7789092, 0.122...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[live, northeastern, united, state, must, snow...</td>\n",
       "      <td>[[[-0.44394183, 0.5360132, -3.1385753, -0.5656...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[gefco, would, allow, cma, cgms, logistics, di...</td>\n",
       "      <td>[[[0.094569094, 0.22194265, -3.1545532, 0.1709...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>[technologically, car, come, long, way, past, ...</td>\n",
       "      <td>[[[1.5262285, 0.7559369, -2.8853347, 0.7643656...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>[ticgard, kepong, professional, window, tint, ...</td>\n",
       "      <td>[[[0.092455335, 1.2149949, -3.5007114, 0.15510...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>[recent, spike, covid, case, impact, operation...</td>\n",
       "      <td>[[[-0.14789566, 0.14471413, -2.9801266, 0.1397...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>[auto, market, reel, costofliving, squeeze, br...</td>\n",
       "      <td>[[[0.2312414, 0.5193047, -2.9179926, 0.2620108...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19951</th>\n",
       "      <td>[care, beyond, point, mass, actually, cheap, l...</td>\n",
       "      <td>[[[0.14510787, 0.3211545, -3.5805924, 0.071578...</td>\n",
       "      <td>automotives</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [november, pv, sale, november, top, pv, sale, ...   \n",
       "1      [visteon, ecarx, jointly, support, lead, inveh...   \n",
       "2      [well, ajay, singh, run, state, bank, india, k...   \n",
       "3      [live, northeastern, united, state, must, snow...   \n",
       "4      [gefco, would, allow, cma, cgms, logistics, di...   \n",
       "...                                                  ...   \n",
       "19947  [technologically, car, come, long, way, past, ...   \n",
       "19948  [ticgard, kepong, professional, window, tint, ...   \n",
       "19949  [recent, spike, covid, case, impact, operation...   \n",
       "19950  [auto, market, reel, costofliving, squeeze, br...   \n",
       "19951  [care, beyond, point, mass, actually, cheap, l...   \n",
       "\n",
       "                                              embeddings       target  \n",
       "0      [[[-0.17716253, 0.20208414, -3.1956387, -0.016...  automotives  \n",
       "1      [[[0.47310433, 0.110844806, -2.8415854, 0.2583...  automotives  \n",
       "2      [[[-0.5193571, -0.086186826, -2.7789092, 0.122...  automotives  \n",
       "3      [[[-0.44394183, 0.5360132, -3.1385753, -0.5656...  automotives  \n",
       "4      [[[0.094569094, 0.22194265, -3.1545532, 0.1709...  automotives  \n",
       "...                                                  ...          ...  \n",
       "19947  [[[1.5262285, 0.7559369, -2.8853347, 0.7643656...  automotives  \n",
       "19948  [[[0.092455335, 1.2149949, -3.5007114, 0.15510...  automotives  \n",
       "19949  [[[-0.14789566, 0.14471413, -2.9801266, 0.1397...  automotives  \n",
       "19950  [[[0.2312414, 0.5193047, -2.9179926, 0.2620108...  automotives  \n",
       "19951  [[[0.14510787, 0.3211545, -3.5805924, 0.071578...  automotives  \n",
       "\n",
       "[19952 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em3 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em3['embeddings'] = category_dfs['automotives'].tokens.apply(generate_embeddings_tiny)\n",
    "em3['tokens'] = category_dfs['automotives'].tokens\n",
    "em3['target'] = 'automotives'\n",
    "em3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa6d43cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "em3.to_pickle('em3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e15f93",
   "metadata": {},
   "source": [
    "### Books and Literature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "820a6d89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[second, book, hidden, series, magnificent, fa...</td>\n",
       "      <td>[[[-0.2825428, -0.25936908, -3.079964, -0.1876...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[gothgirl, raven, date, dream, boyfriend, comp...</td>\n",
       "      <td>[[[-0.19218545, -1.5018293, -1.7651486, -0.363...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bengaluru, former, bureaucrat, manu, baligar,...</td>\n",
       "      <td>[[[0.024343587, -1.166749, -2.9484146, 0.32971...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[volume, put, together, first, time, one, volu...</td>\n",
       "      <td>[[[-0.3353019, -1.6676707, -2.9380536, 0.31712...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[director, randhir, ranjan, roycast, shekhar, ...</td>\n",
       "      <td>[[[-0.106702626, -1.2725184, -3.032748, -0.055...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19555</th>\n",
       "      <td>[claire, river, race, mailbox, receive, letter...</td>\n",
       "      <td>[[[-0.7836311, -1.1047237, -2.965418, 0.099996...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19556</th>\n",
       "      <td>[nearly, twenty, year, live, california, march...</td>\n",
       "      <td>[[[-1.000156, -0.7927231, -3.6281798, -0.36086...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19557</th>\n",
       "      <td>[j, r, longawaited, novel, william, gaddi, aut...</td>\n",
       "      <td>[[[-0.64479095, -0.47847453, -2.8149726, 0.381...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19558</th>\n",
       "      <td>[john, braines, remarkable, first, novel, room...</td>\n",
       "      <td>[[[-0.40121478, -0.41362193, -3.563855, -0.252...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19559</th>\n",
       "      <td>[thiruvananthapuram, eminent, malayalam, write...</td>\n",
       "      <td>[[[0.38977742, -0.43465108, -2.7940845, 0.0830...</td>\n",
       "      <td>books and literature</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19560 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [second, book, hidden, series, magnificent, fa...   \n",
       "1      [gothgirl, raven, date, dream, boyfriend, comp...   \n",
       "2      [bengaluru, former, bureaucrat, manu, baligar,...   \n",
       "3      [volume, put, together, first, time, one, volu...   \n",
       "4      [director, randhir, ranjan, roycast, shekhar, ...   \n",
       "...                                                  ...   \n",
       "19555  [claire, river, race, mailbox, receive, letter...   \n",
       "19556  [nearly, twenty, year, live, california, march...   \n",
       "19557  [j, r, longawaited, novel, william, gaddi, aut...   \n",
       "19558  [john, braines, remarkable, first, novel, room...   \n",
       "19559  [thiruvananthapuram, eminent, malayalam, write...   \n",
       "\n",
       "                                              embeddings                target  \n",
       "0      [[[-0.2825428, -0.25936908, -3.079964, -0.1876...  books and literature  \n",
       "1      [[[-0.19218545, -1.5018293, -1.7651486, -0.363...  books and literature  \n",
       "2      [[[0.024343587, -1.166749, -2.9484146, 0.32971...  books and literature  \n",
       "3      [[[-0.3353019, -1.6676707, -2.9380536, 0.31712...  books and literature  \n",
       "4      [[[-0.106702626, -1.2725184, -3.032748, -0.055...  books and literature  \n",
       "...                                                  ...                   ...  \n",
       "19555  [[[-0.7836311, -1.1047237, -2.965418, 0.099996...  books and literature  \n",
       "19556  [[[-1.000156, -0.7927231, -3.6281798, -0.36086...  books and literature  \n",
       "19557  [[[-0.64479095, -0.47847453, -2.8149726, 0.381...  books and literature  \n",
       "19558  [[[-0.40121478, -0.41362193, -3.563855, -0.252...  books and literature  \n",
       "19559  [[[0.38977742, -0.43465108, -2.7940845, 0.0830...  books and literature  \n",
       "\n",
       "[19560 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em4 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em4['embeddings'] = category_dfs['books and literature'].tokens.apply(generate_embeddings_tiny)\n",
    "em4['tokens'] = category_dfs['books and literature'].tokens\n",
    "em4['target'] = 'books and literature'\n",
    "em4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "560c97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "em4.to_pickle('em4.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24ba55c",
   "metadata": {},
   "source": [
    "## Business and Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d735e5c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[kolkata, state, cabinet, monday, give, approv...</td>\n",
       "      <td>[[[0.0911726, 0.74755377, -3.6008031, 0.271776...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[bangalore, microfinance, institution, mfis, f...</td>\n",
       "      <td>[[[0.3205924, 0.3929392, -3.436069, 0.22018968...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[new, delhi, three, month, rollout, new, indir...</td>\n",
       "      <td>[[[-0.08207576, 0.53871995, -3.0617993, 0.1523...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[new, delhi, apr, concern, recent, case, highi...</td>\n",
       "      <td>[[[-0.4567737, 0.6693551, -3.535691, 0.2574101...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tweens, spend, report, billion, money, year, ...</td>\n",
       "      <td>[[[-0.86273414, 0.30044192, -3.441955, -0.3264...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19899</th>\n",
       "      <td>[possible, go, event, learn, attendance, way, ...</td>\n",
       "      <td>[[[-0.7226761, -0.15505208, -3.846671, -0.3285...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19900</th>\n",
       "      <td>[kolkata, niti, aayog, order, detailed, evalua...</td>\n",
       "      <td>[[[-0.64313596, 0.9769468, -3.4688451, 0.20175...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>[div, classsectiondiv, classnormalthe, institu...</td>\n",
       "      <td>[[[0.11353982, 1.0613956, -2.9931672, 0.170397...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19902</th>\n",
       "      <td>[keep, lowdenomination, currency, circulation,...</td>\n",
       "      <td>[[[-0.31344014, 0.38000175, -3.1935112, -0.053...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>[mumbai, sep, gold, loan, financier, see, rise...</td>\n",
       "      <td>[[[0.03685022, 0.61938345, -3.252787, 0.255715...</td>\n",
       "      <td>business and finance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [kolkata, state, cabinet, monday, give, approv...   \n",
       "1      [bangalore, microfinance, institution, mfis, f...   \n",
       "2      [new, delhi, three, month, rollout, new, indir...   \n",
       "3      [new, delhi, apr, concern, recent, case, highi...   \n",
       "4      [tweens, spend, report, billion, money, year, ...   \n",
       "...                                                  ...   \n",
       "19899  [possible, go, event, learn, attendance, way, ...   \n",
       "19900  [kolkata, niti, aayog, order, detailed, evalua...   \n",
       "19901  [div, classsectiondiv, classnormalthe, institu...   \n",
       "19902  [keep, lowdenomination, currency, circulation,...   \n",
       "19903  [mumbai, sep, gold, loan, financier, see, rise...   \n",
       "\n",
       "                                              embeddings                target  \n",
       "0      [[[0.0911726, 0.74755377, -3.6008031, 0.271776...  business and finance  \n",
       "1      [[[0.3205924, 0.3929392, -3.436069, 0.22018968...  business and finance  \n",
       "2      [[[-0.08207576, 0.53871995, -3.0617993, 0.1523...  business and finance  \n",
       "3      [[[-0.4567737, 0.6693551, -3.535691, 0.2574101...  business and finance  \n",
       "4      [[[-0.86273414, 0.30044192, -3.441955, -0.3264...  business and finance  \n",
       "...                                                  ...                   ...  \n",
       "19899  [[[-0.7226761, -0.15505208, -3.846671, -0.3285...  business and finance  \n",
       "19900  [[[-0.64313596, 0.9769468, -3.4688451, 0.20175...  business and finance  \n",
       "19901  [[[0.11353982, 1.0613956, -2.9931672, 0.170397...  business and finance  \n",
       "19902  [[[-0.31344014, 0.38000175, -3.1935112, -0.053...  business and finance  \n",
       "19903  [[[0.03685022, 0.61938345, -3.252787, 0.255715...  business and finance  \n",
       "\n",
       "[19904 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em5 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em5['embeddings'] = category_dfs['business and finance'].tokens.apply(generate_embeddings_tiny)\n",
    "em5['tokens'] = category_dfs['business and finance'].tokens\n",
    "em5['target'] = 'business and finance'\n",
    "em5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0e36d685",
   "metadata": {},
   "outputs": [],
   "source": [
    "em5.to_pickle('em5.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd86a7e",
   "metadata": {},
   "source": [
    "### Careers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0baa5912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[job, title, business, administrator, hour, mo...</td>\n",
       "      <td>[[[-1.1585404, -0.00519662, -3.2329836, 0.0706...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[engineer, new, career, lead, blue, chip, expe...</td>\n",
       "      <td>[[[0.04865677, 1.3955913, -3.3475652, 0.491545...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[commis, chef, exclusive, contract, caterer, c...</td>\n",
       "      <td>[[[-0.90891796, 0.40885755, -2.793777, 0.19815...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[research, nurse, full, training, offer, becom...</td>\n",
       "      <td>[[[-0.07078594, 1.3081, -3.0679877, 0.36670458...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[client, client, lead, high, street, restauran...</td>\n",
       "      <td>[[[-0.67467016, 0.8129236, -3.2634115, 0.04475...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19766</th>\n",
       "      <td>[harbour, jones, lead, independent, innovative...</td>\n",
       "      <td>[[[-0.2160252, 0.5863335, -3.2974331, 0.058317...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19767</th>\n",
       "      <td>[jr, data, scientist, share, find, similar, ca...</td>\n",
       "      <td>[[[-0.16756666, 0.9754682, -3.0515275, 0.56872...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19768</th>\n",
       "      <td>[client, look, lamp, development, system, engi...</td>\n",
       "      <td>[[[0.3251138, 0.7110735, -2.8631787, 0.2766041...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19769</th>\n",
       "      <td>[customer, contact, centre, case, officer, lee...</td>\n",
       "      <td>[[[-0.17721274, 0.8589781, -2.951778, 0.510923...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19770</th>\n",
       "      <td>[work, digital, agency, unique, offering, brin...</td>\n",
       "      <td>[[[-0.19897321, 0.5831546, -2.9702802, 0.15021...</td>\n",
       "      <td>careers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19771 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [job, title, business, administrator, hour, mo...   \n",
       "1      [engineer, new, career, lead, blue, chip, expe...   \n",
       "2      [commis, chef, exclusive, contract, caterer, c...   \n",
       "3      [research, nurse, full, training, offer, becom...   \n",
       "4      [client, client, lead, high, street, restauran...   \n",
       "...                                                  ...   \n",
       "19766  [harbour, jones, lead, independent, innovative...   \n",
       "19767  [jr, data, scientist, share, find, similar, ca...   \n",
       "19768  [client, look, lamp, development, system, engi...   \n",
       "19769  [customer, contact, centre, case, officer, lee...   \n",
       "19770  [work, digital, agency, unique, offering, brin...   \n",
       "\n",
       "                                              embeddings   target  \n",
       "0      [[[-1.1585404, -0.00519662, -3.2329836, 0.0706...  careers  \n",
       "1      [[[0.04865677, 1.3955913, -3.3475652, 0.491545...  careers  \n",
       "2      [[[-0.90891796, 0.40885755, -2.793777, 0.19815...  careers  \n",
       "3      [[[-0.07078594, 1.3081, -3.0679877, 0.36670458...  careers  \n",
       "4      [[[-0.67467016, 0.8129236, -3.2634115, 0.04475...  careers  \n",
       "...                                                  ...      ...  \n",
       "19766  [[[-0.2160252, 0.5863335, -3.2974331, 0.058317...  careers  \n",
       "19767  [[[-0.16756666, 0.9754682, -3.0515275, 0.56872...  careers  \n",
       "19768  [[[0.3251138, 0.7110735, -2.8631787, 0.2766041...  careers  \n",
       "19769  [[[-0.17721274, 0.8589781, -2.951778, 0.510923...  careers  \n",
       "19770  [[[-0.19897321, 0.5831546, -2.9702802, 0.15021...  careers  \n",
       "\n",
       "[19771 rows x 3 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em6 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em6['embeddings'] = category_dfs['careers'].tokens.apply(generate_embeddings_tiny)\n",
    "em6['tokens'] = category_dfs['careers'].tokens\n",
    "em6['target'] = 'careers'\n",
    "em6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "14972201",
   "metadata": {},
   "outputs": [],
   "source": [
    "em6.to_pickle('em6.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d17c9c7",
   "metadata": {},
   "source": [
    "### Family and Relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6ccca23b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[kannada, actress, aishwarya, salimath, ready,...</td>\n",
       "      <td>[[[0.304279, -1.0870881, -3.142775, 0.15681927...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[new, delhi, delhi, commission, woman, dcw, mo...</td>\n",
       "      <td>[[[-0.36702198, -0.37194413, -3.2135088, -0.25...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[mumbai, delhi, police, continue, record, stat...</td>\n",
       "      <td>[[[-0.21959215, -0.79908043, -3.2901754, -0.07...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[nagpur, durupyog, play, noga, wasahat, indora...</td>\n",
       "      <td>[[[-0.035072193, -0.6475075, -3.5538352, -0.02...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[chennai, police, find, body, yearold, homemak...</td>\n",
       "      <td>[[[-0.2150374, 0.104187906, -3.212747, -0.1802...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19835</th>\n",
       "      <td>[britain, continue, hold, sign, similar, deala...</td>\n",
       "      <td>[[[-0.084167406, -0.40989447, -3.4159968, 0.22...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19836</th>\n",
       "      <td>[wendy, will, date, indian, man, learn, tough,...</td>\n",
       "      <td>[[[-0.5072417, -1.0377429, -3.3171778, -0.0409...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19837</th>\n",
       "      <td>[quite, year, rashmika, mandanna, college, stu...</td>\n",
       "      <td>[[[-0.457272, -1.1840553, -3.3248122, -0.15570...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19838</th>\n",
       "      <td>[pune, yearold, youth, arrest, thursday, day, ...</td>\n",
       "      <td>[[[-0.9869819, -0.61783266, -3.435388, -0.4391...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19839</th>\n",
       "      <td>[actor, renuka, shahane, marry, ashutosh, rana...</td>\n",
       "      <td>[[[-0.17193604, -0.8788904, -3.4084992, 0.1775...</td>\n",
       "      <td>family and relationships</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19840 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [kannada, actress, aishwarya, salimath, ready,...   \n",
       "1      [new, delhi, delhi, commission, woman, dcw, mo...   \n",
       "2      [mumbai, delhi, police, continue, record, stat...   \n",
       "3      [nagpur, durupyog, play, noga, wasahat, indora...   \n",
       "4      [chennai, police, find, body, yearold, homemak...   \n",
       "...                                                  ...   \n",
       "19835  [britain, continue, hold, sign, similar, deala...   \n",
       "19836  [wendy, will, date, indian, man, learn, tough,...   \n",
       "19837  [quite, year, rashmika, mandanna, college, stu...   \n",
       "19838  [pune, yearold, youth, arrest, thursday, day, ...   \n",
       "19839  [actor, renuka, shahane, marry, ashutosh, rana...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [[[0.304279, -1.0870881, -3.142775, 0.15681927...   \n",
       "1      [[[-0.36702198, -0.37194413, -3.2135088, -0.25...   \n",
       "2      [[[-0.21959215, -0.79908043, -3.2901754, -0.07...   \n",
       "3      [[[-0.035072193, -0.6475075, -3.5538352, -0.02...   \n",
       "4      [[[-0.2150374, 0.104187906, -3.212747, -0.1802...   \n",
       "...                                                  ...   \n",
       "19835  [[[-0.084167406, -0.40989447, -3.4159968, 0.22...   \n",
       "19836  [[[-0.5072417, -1.0377429, -3.3171778, -0.0409...   \n",
       "19837  [[[-0.457272, -1.1840553, -3.3248122, -0.15570...   \n",
       "19838  [[[-0.9869819, -0.61783266, -3.435388, -0.4391...   \n",
       "19839  [[[-0.17193604, -0.8788904, -3.4084992, 0.1775...   \n",
       "\n",
       "                         target  \n",
       "0      family and relationships  \n",
       "1      family and relationships  \n",
       "2      family and relationships  \n",
       "3      family and relationships  \n",
       "4      family and relationships  \n",
       "...                         ...  \n",
       "19835  family and relationships  \n",
       "19836  family and relationships  \n",
       "19837  family and relationships  \n",
       "19838  family and relationships  \n",
       "19839  family and relationships  \n",
       "\n",
       "[19840 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em7 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em7['embeddings'] = category_dfs['family and relationships'].tokens.apply(generate_embeddings_tiny)\n",
    "em7['tokens'] = category_dfs['family and relationships'].tokens\n",
    "em7['target'] = 'family and relationships'\n",
    "em7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32fcda5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "em7.to_pickle('em7.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b4d144",
   "metadata": {},
   "source": [
    "### Food and Drinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8b9aa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[thane, hold, three, acre, fertile, agricultur...</td>\n",
       "      <td>[[[-0.89286274, 0.38927057, -3.8541615, 0.0964...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[pune, doctor, notice, considerable, increase,...</td>\n",
       "      <td>[[[-0.8821945, -0.2555993, -3.8379261, 0.57442...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[final, solution, destitute, home, recovery, h...</td>\n",
       "      <td>[[[-0.19585092, -0.3291104, -4.608773, -0.0515...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[northwestern, turkey, city, canakkale, tragic...</td>\n",
       "      <td>[[[-0.777349, -1.0547625, -3.6468453, -0.02063...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[yearsno, dance, seat, areasno, professional, ...</td>\n",
       "      <td>[[[-0.7180602, 0.8021013, -3.5800729, 0.563734...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19920</th>\n",
       "      <td>[india, kisan, sangarsh, coordination, committ...</td>\n",
       "      <td>[[[0.08656999, 0.116289325, -3.062819, -0.0683...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19921</th>\n",
       "      <td>[actress, shruti, haasan, last, see, telugu, f...</td>\n",
       "      <td>[[[0.08504137, -1.0277011, -2.6771984, -0.0684...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>[skip, bouquet, petalladen, bubble, bath, put,...</td>\n",
       "      <td>[[[-1.5274739, 0.3091327, -2.775981, 0.1426840...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>[night, march, first, felt, dryness, throat, m...</td>\n",
       "      <td>[[[-1.3973497, -0.61010927, -3.8240838, 0.2246...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <td>[puducherry, union, territory, police, monday,...</td>\n",
       "      <td>[[[-0.038324855, 0.22431165, -3.3873694, 0.162...</td>\n",
       "      <td>food and drinks</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19925 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [thane, hold, three, acre, fertile, agricultur...   \n",
       "1      [pune, doctor, notice, considerable, increase,...   \n",
       "2      [final, solution, destitute, home, recovery, h...   \n",
       "3      [northwestern, turkey, city, canakkale, tragic...   \n",
       "4      [yearsno, dance, seat, areasno, professional, ...   \n",
       "...                                                  ...   \n",
       "19920  [india, kisan, sangarsh, coordination, committ...   \n",
       "19921  [actress, shruti, haasan, last, see, telugu, f...   \n",
       "19922  [skip, bouquet, petalladen, bubble, bath, put,...   \n",
       "19923  [night, march, first, felt, dryness, throat, m...   \n",
       "19924  [puducherry, union, territory, police, monday,...   \n",
       "\n",
       "                                              embeddings           target  \n",
       "0      [[[-0.89286274, 0.38927057, -3.8541615, 0.0964...  food and drinks  \n",
       "1      [[[-0.8821945, -0.2555993, -3.8379261, 0.57442...  food and drinks  \n",
       "2      [[[-0.19585092, -0.3291104, -4.608773, -0.0515...  food and drinks  \n",
       "3      [[[-0.777349, -1.0547625, -3.6468453, -0.02063...  food and drinks  \n",
       "4      [[[-0.7180602, 0.8021013, -3.5800729, 0.563734...  food and drinks  \n",
       "...                                                  ...              ...  \n",
       "19920  [[[0.08656999, 0.116289325, -3.062819, -0.0683...  food and drinks  \n",
       "19921  [[[0.08504137, -1.0277011, -2.6771984, -0.0684...  food and drinks  \n",
       "19922  [[[-1.5274739, 0.3091327, -2.775981, 0.1426840...  food and drinks  \n",
       "19923  [[[-1.3973497, -0.61010927, -3.8240838, 0.2246...  food and drinks  \n",
       "19924  [[[-0.038324855, 0.22431165, -3.3873694, 0.162...  food and drinks  \n",
       "\n",
       "[19925 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em8 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em8['embeddings'] = category_dfs['food and drinks'].tokens.apply(generate_embeddings_tiny)\n",
    "em8['tokens'] = category_dfs['food and drinks'].tokens\n",
    "em8['target'] = 'food and drinks'\n",
    "em8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b3c9da7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "em8.to_pickle('em8.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2161910",
   "metadata": {},
   "source": [
    "### Health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ead93629",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nashik, maharashtra, university, health, scie...</td>\n",
       "      <td>[[[-0.49349752, 0.16173358, -3.4336412, 0.0459...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[patna, second, wave, covid, pandemic, proving...</td>\n",
       "      <td>[[[-1.2958199, -1.0256163, -3.810895, -0.15837...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[patna, chief, minister, nitish, kumar, thursd...</td>\n",
       "      <td>[[[0.14134955, 0.8486043, -3.368295, -0.004928...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[chennai, containment, effort, intensify, acro...</td>\n",
       "      <td>[[[0.08557642, -0.36385408, -3.5297587, 0.1571...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[shimla, use, mask, glove, increase, manifold,...</td>\n",
       "      <td>[[[-0.5708977, 0.6764543, -3.6741345, 0.337997...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19914</th>\n",
       "      <td>[new, delhi, global, covid, case, surge, due, ...</td>\n",
       "      <td>[[[-0.4846878, -0.02270529, -3.8856761, 0.3714...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19915</th>\n",
       "      <td>[patna, third, phase, nationwide, covid, vacci...</td>\n",
       "      <td>[[[-1.0378103, -0.24870321, -3.9698696, -0.204...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19916</th>\n",
       "      <td>[chandigarh, march, record, almost, sixtime, s...</td>\n",
       "      <td>[[[-0.51937485, -0.18387397, -3.7230113, 0.125...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19917</th>\n",
       "      <td>[four, month, age, group, complete, target, fi...</td>\n",
       "      <td>[[[-0.8412075, 0.7411999, -3.620757, 0.1963848...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19918</th>\n",
       "      <td>[health, risk, child, older, adult, people, he...</td>\n",
       "      <td>[[[-0.7331219, 0.29589027, -3.6596754, 0.57349...</td>\n",
       "      <td>health</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19919 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [nashik, maharashtra, university, health, scie...   \n",
       "1      [patna, second, wave, covid, pandemic, proving...   \n",
       "2      [patna, chief, minister, nitish, kumar, thursd...   \n",
       "3      [chennai, containment, effort, intensify, acro...   \n",
       "4      [shimla, use, mask, glove, increase, manifold,...   \n",
       "...                                                  ...   \n",
       "19914  [new, delhi, global, covid, case, surge, due, ...   \n",
       "19915  [patna, third, phase, nationwide, covid, vacci...   \n",
       "19916  [chandigarh, march, record, almost, sixtime, s...   \n",
       "19917  [four, month, age, group, complete, target, fi...   \n",
       "19918  [health, risk, child, older, adult, people, he...   \n",
       "\n",
       "                                              embeddings  target  \n",
       "0      [[[-0.49349752, 0.16173358, -3.4336412, 0.0459...  health  \n",
       "1      [[[-1.2958199, -1.0256163, -3.810895, -0.15837...  health  \n",
       "2      [[[0.14134955, 0.8486043, -3.368295, -0.004928...  health  \n",
       "3      [[[0.08557642, -0.36385408, -3.5297587, 0.1571...  health  \n",
       "4      [[[-0.5708977, 0.6764543, -3.6741345, 0.337997...  health  \n",
       "...                                                  ...     ...  \n",
       "19914  [[[-0.4846878, -0.02270529, -3.8856761, 0.3714...  health  \n",
       "19915  [[[-1.0378103, -0.24870321, -3.9698696, -0.204...  health  \n",
       "19916  [[[-0.51937485, -0.18387397, -3.7230113, 0.125...  health  \n",
       "19917  [[[-0.8412075, 0.7411999, -3.620757, 0.1963848...  health  \n",
       "19918  [[[-0.7331219, 0.29589027, -3.6596754, 0.57349...  health  \n",
       "\n",
       "[19919 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em9 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em9['embeddings'] = category_dfs['health'].tokens.apply(generate_embeddings_tiny)\n",
    "em9['tokens'] = category_dfs['health'].tokens\n",
    "em9['target'] = 'health'\n",
    "em9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38378514",
   "metadata": {},
   "outputs": [],
   "source": [
    "em9.to_pickle('em9.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fa7bc5",
   "metadata": {},
   "source": [
    "### Healthy Living"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "370fdfb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[underlie, medical, issue, like, vitamin, defi...</td>\n",
       "      <td>[[[-1.3867143, -0.27297005, -3.760375, 0.00810...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[stage, grief, mean, tell, feel, feel, exactly...</td>\n",
       "      <td>[[[-1.1821362, 0.13037188, -4.118121, -0.24336...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[youre, among, always, experiment, western, fa...</td>\n",
       "      <td>[[[-1.1084658, -0.47295836, -3.8224232, 0.6352...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[lucknow, equate, tobacco, weapon, mass, destr...</td>\n",
       "      <td>[[[-0.79914975, 0.21350126, -3.2756097, 0.3369...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[criminal, investigation, underway, six, peopl...</td>\n",
       "      <td>[[[-0.69551885, -0.5339499, -3.260872, 0.13407...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19852</th>\n",
       "      <td>[ahmedabad, vinay, oza, call, change, engineer...</td>\n",
       "      <td>[[[-0.9231463, -0.508992, -3.6553776, 0.025694...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19853</th>\n",
       "      <td>[introchances, one, first, place, turn, quick,...</td>\n",
       "      <td>[[[-0.52816385, -0.046133887, -3.2741027, 0.38...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19854</th>\n",
       "      <td>[key, manage, conflict, first, foremost, recog...</td>\n",
       "      <td>[[[-0.606227, -0.9007104, -3.56591, -0.2519776...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19855</th>\n",
       "      <td>[christmas, fever, get, everyone, infect, thus...</td>\n",
       "      <td>[[[-0.5183787, -0.92671597, -2.9370725, 0.0727...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19856</th>\n",
       "      <td>[six, month, ago, decide, take, plunge, get, c...</td>\n",
       "      <td>[[[-1.5021117, 0.19900088, -4.4042153, -0.5075...</td>\n",
       "      <td>healthy living</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19857 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [underlie, medical, issue, like, vitamin, defi...   \n",
       "1      [stage, grief, mean, tell, feel, feel, exactly...   \n",
       "2      [youre, among, always, experiment, western, fa...   \n",
       "3      [lucknow, equate, tobacco, weapon, mass, destr...   \n",
       "4      [criminal, investigation, underway, six, peopl...   \n",
       "...                                                  ...   \n",
       "19852  [ahmedabad, vinay, oza, call, change, engineer...   \n",
       "19853  [introchances, one, first, place, turn, quick,...   \n",
       "19854  [key, manage, conflict, first, foremost, recog...   \n",
       "19855  [christmas, fever, get, everyone, infect, thus...   \n",
       "19856  [six, month, ago, decide, take, plunge, get, c...   \n",
       "\n",
       "                                              embeddings          target  \n",
       "0      [[[-1.3867143, -0.27297005, -3.760375, 0.00810...  healthy living  \n",
       "1      [[[-1.1821362, 0.13037188, -4.118121, -0.24336...  healthy living  \n",
       "2      [[[-1.1084658, -0.47295836, -3.8224232, 0.6352...  healthy living  \n",
       "3      [[[-0.79914975, 0.21350126, -3.2756097, 0.3369...  healthy living  \n",
       "4      [[[-0.69551885, -0.5339499, -3.260872, 0.13407...  healthy living  \n",
       "...                                                  ...             ...  \n",
       "19852  [[[-0.9231463, -0.508992, -3.6553776, 0.025694...  healthy living  \n",
       "19853  [[[-0.52816385, -0.046133887, -3.2741027, 0.38...  healthy living  \n",
       "19854  [[[-0.606227, -0.9007104, -3.56591, -0.2519776...  healthy living  \n",
       "19855  [[[-0.5183787, -0.92671597, -2.9370725, 0.0727...  healthy living  \n",
       "19856  [[[-1.5021117, 0.19900088, -4.4042153, -0.5075...  healthy living  \n",
       "\n",
       "[19857 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em10 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em10['embeddings'] = category_dfs['healthy living'].tokens.apply(generate_embeddings_tiny)\n",
    "em10['tokens'] = category_dfs['healthy living'].tokens\n",
    "em10['target'] = 'healthy living'\n",
    "em10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a77a60ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "em10.to_pickle('em10.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d226cb4",
   "metadata": {},
   "source": [
    "### Hobbies and Interests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "107eddf5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[arent, satoshi, tajiri, japanese, designer, i...</td>\n",
       "      <td>[[[-0.2694938, 0.09765025, -2.8648136, 0.52382...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[president, trump, pick, replace, antonin, sca...</td>\n",
       "      <td>[[[-0.6226243, 0.44487563, -3.1528907, 0.22189...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[hardly, occasion, software, professional, aru...</td>\n",
       "      <td>[[[-0.47292283, -0.6018179, -3.0143802, -0.159...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[program, help, explore, write, workshop, kid,...</td>\n",
       "      <td>[[[-0.16380717, -0.35520393, -2.790352, -0.232...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[new, delhi, royal, mail, go, credit, populari...</td>\n",
       "      <td>[[[0.59272075, 0.050216153, -2.1634223, 0.1146...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19865</th>\n",
       "      <td>[ayushmann, khurrana, apply, fly, license, you...</td>\n",
       "      <td>[[[-0.77498037, 0.2511254, -3.6647441, -0.2540...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19866</th>\n",
       "      <td>[come, together, many, artist, art, lover, cit...</td>\n",
       "      <td>[[[0.06208185, 0.10280193, -2.8320336, -0.2137...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19867</th>\n",
       "      <td>[tv, industry, know, gruelling, schedule, long...</td>\n",
       "      <td>[[[-0.5232618, -1.2991542, -3.1910439, -0.1434...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19868</th>\n",
       "      <td>[visakhapatnam, newly, year, new, beginning, n...</td>\n",
       "      <td>[[[-0.79463696, -0.19966453, -3.5019412, 0.432...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19869</th>\n",
       "      <td>[singh, claim, pay, monthly, bill, sims, posse...</td>\n",
       "      <td>[[[0.4917924, -0.19129544, -2.9983222, 0.25645...</td>\n",
       "      <td>hobbies and interests</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19870 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [arent, satoshi, tajiri, japanese, designer, i...   \n",
       "1      [president, trump, pick, replace, antonin, sca...   \n",
       "2      [hardly, occasion, software, professional, aru...   \n",
       "3      [program, help, explore, write, workshop, kid,...   \n",
       "4      [new, delhi, royal, mail, go, credit, populari...   \n",
       "...                                                  ...   \n",
       "19865  [ayushmann, khurrana, apply, fly, license, you...   \n",
       "19866  [come, together, many, artist, art, lover, cit...   \n",
       "19867  [tv, industry, know, gruelling, schedule, long...   \n",
       "19868  [visakhapatnam, newly, year, new, beginning, n...   \n",
       "19869  [singh, claim, pay, monthly, bill, sims, posse...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [[[-0.2694938, 0.09765025, -2.8648136, 0.52382...   \n",
       "1      [[[-0.6226243, 0.44487563, -3.1528907, 0.22189...   \n",
       "2      [[[-0.47292283, -0.6018179, -3.0143802, -0.159...   \n",
       "3      [[[-0.16380717, -0.35520393, -2.790352, -0.232...   \n",
       "4      [[[0.59272075, 0.050216153, -2.1634223, 0.1146...   \n",
       "...                                                  ...   \n",
       "19865  [[[-0.77498037, 0.2511254, -3.6647441, -0.2540...   \n",
       "19866  [[[0.06208185, 0.10280193, -2.8320336, -0.2137...   \n",
       "19867  [[[-0.5232618, -1.2991542, -3.1910439, -0.1434...   \n",
       "19868  [[[-0.79463696, -0.19966453, -3.5019412, 0.432...   \n",
       "19869  [[[0.4917924, -0.19129544, -2.9983222, 0.25645...   \n",
       "\n",
       "                      target  \n",
       "0      hobbies and interests  \n",
       "1      hobbies and interests  \n",
       "2      hobbies and interests  \n",
       "3      hobbies and interests  \n",
       "4      hobbies and interests  \n",
       "...                      ...  \n",
       "19865  hobbies and interests  \n",
       "19866  hobbies and interests  \n",
       "19867  hobbies and interests  \n",
       "19868  hobbies and interests  \n",
       "19869  hobbies and interests  \n",
       "\n",
       "[19870 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em11 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em11['embeddings'] = category_dfs['hobbies and interests'].tokens.apply(generate_embeddings_tiny)\n",
    "em11['tokens'] = category_dfs['hobbies and interests'].tokens\n",
    "em11['target'] = 'hobbies and interests'\n",
    "\n",
    "em11.to_pickle('em11.pkl')\n",
    "em11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddd9f27",
   "metadata": {},
   "source": [
    "### Home and Garden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89593053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[unsolicited, valentine, day, public, service,...</td>\n",
       "      <td>[[[-0.25100556, -0.45264766, -3.2467463, -0.00...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[new, delhi, tailormade, low, bounce, fast, gr...</td>\n",
       "      <td>[[[-0.29474416, -0.524027, -3.1594148, 0.13122...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[married, couple, spouse, increase, togetherne...</td>\n",
       "      <td>[[[-0.34036943, -0.39640787, -3.2539332, 0.535...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[advice, take, care, farm, yamanappa, benefici...</td>\n",
       "      <td>[[[-0.53721505, 0.66947156, -3.8469877, -0.194...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[thousand, goans, tourist, alike, flock, samba...</td>\n",
       "      <td>[[[-0.65053195, -0.42067775, -2.7230961, 0.274...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19905</th>\n",
       "      <td>[hyderabad, telangana, rashtra, samithi, trs, ...</td>\n",
       "      <td>[[[0.06893284, 0.25188923, -3.0283227, -0.3183...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19906</th>\n",
       "      <td>[vijaywada, vijayawada, municipal, corporation...</td>\n",
       "      <td>[[[-0.44642287, 0.5116569, -3.6761794, 0.04894...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19907</th>\n",
       "      <td>[th, defeat, season, new, york, pull, point, l...</td>\n",
       "      <td>[[[-0.52231103, -1.1759918, -3.0533473, 0.5295...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19908</th>\n",
       "      <td>[bengaluru, nationwide, lockdown, enforce, res...</td>\n",
       "      <td>[[[-0.86091477, 0.5236266, -3.5441372, 0.22286...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19909</th>\n",
       "      <td>[get, marry, settle, us, say, take, rajgopalan...</td>\n",
       "      <td>[[[-0.40980148, -0.33607054, -3.2426887, -0.17...</td>\n",
       "      <td>home and garden</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19910 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [unsolicited, valentine, day, public, service,...   \n",
       "1      [new, delhi, tailormade, low, bounce, fast, gr...   \n",
       "2      [married, couple, spouse, increase, togetherne...   \n",
       "3      [advice, take, care, farm, yamanappa, benefici...   \n",
       "4      [thousand, goans, tourist, alike, flock, samba...   \n",
       "...                                                  ...   \n",
       "19905  [hyderabad, telangana, rashtra, samithi, trs, ...   \n",
       "19906  [vijaywada, vijayawada, municipal, corporation...   \n",
       "19907  [th, defeat, season, new, york, pull, point, l...   \n",
       "19908  [bengaluru, nationwide, lockdown, enforce, res...   \n",
       "19909  [get, marry, settle, us, say, take, rajgopalan...   \n",
       "\n",
       "                                              embeddings           target  \n",
       "0      [[[-0.25100556, -0.45264766, -3.2467463, -0.00...  home and garden  \n",
       "1      [[[-0.29474416, -0.524027, -3.1594148, 0.13122...  home and garden  \n",
       "2      [[[-0.34036943, -0.39640787, -3.2539332, 0.535...  home and garden  \n",
       "3      [[[-0.53721505, 0.66947156, -3.8469877, -0.194...  home and garden  \n",
       "4      [[[-0.65053195, -0.42067775, -2.7230961, 0.274...  home and garden  \n",
       "...                                                  ...              ...  \n",
       "19905  [[[0.06893284, 0.25188923, -3.0283227, -0.3183...  home and garden  \n",
       "19906  [[[-0.44642287, 0.5116569, -3.6761794, 0.04894...  home and garden  \n",
       "19907  [[[-0.52231103, -1.1759918, -3.0533473, 0.5295...  home and garden  \n",
       "19908  [[[-0.86091477, 0.5236266, -3.5441372, 0.22286...  home and garden  \n",
       "19909  [[[-0.40980148, -0.33607054, -3.2426887, -0.17...  home and garden  \n",
       "\n",
       "[19910 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em12 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em12['embeddings'] = category_dfs['home and garden'].tokens.apply(generate_embeddings_tiny)\n",
    "em12['tokens'] = category_dfs['home and garden'].tokens\n",
    "em12['target'] = 'home and garden'\n",
    "\n",
    "em12.to_pickle('em12.pkl')\n",
    "em12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632bc612",
   "metadata": {},
   "source": [
    "### Movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e338fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[crew, member, help, make, directorial, debut,...</td>\n",
       "      <td>[[[0.12024946, -0.78567064, -3.5644288, -0.227...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[raven, chooses, orgasm, part, one, fantasy, s...</td>\n",
       "      <td>[[[-0.48352894, -0.8714409, -2.9694452, -0.066...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[kourtney, kardashian, scott, disick, split, a...</td>\n",
       "      <td>[[[-0.7423043, -0.09902109, -3.5733092, -0.453...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[time, problem, fan, noticeable, promotion, pr...</td>\n",
       "      <td>[[[-0.693424, 0.0857078, -3.565634, -0.3289777...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mammootty, hint, yet, another, blockbuster, t...</td>\n",
       "      <td>[[[0.7594643, -0.7104957, -2.6859756, 0.063971...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19959</th>\n",
       "      <td>[sanya, malhotra, await, release, next, kathal...</td>\n",
       "      <td>[[[0.17818275, -1.2513094, -3.4496045, -0.0817...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>[muchawaited, telugu, film, agent, star, akhil...</td>\n",
       "      <td>[[[0.45222053, -0.9803299, -3.006483, 0.348450...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19961</th>\n",
       "      <td>[music, composer, rahul, raj, busy, compose, s...</td>\n",
       "      <td>[[[0.3546554, -0.8488461, -2.8696122, -0.22280...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19962</th>\n",
       "      <td>[anil, sharma, back, sequel, iconic, gadar, ye...</td>\n",
       "      <td>[[[0.3361115, -0.86924994, -3.014597, -0.07367...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>[actor, karthi, last, see, tamil, film, ponniy...</td>\n",
       "      <td>[[[1.341891, -1.0856631, -2.7355123, 0.0883205...</td>\n",
       "      <td>movies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19964 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [crew, member, help, make, directorial, debut,...   \n",
       "1      [raven, chooses, orgasm, part, one, fantasy, s...   \n",
       "2      [kourtney, kardashian, scott, disick, split, a...   \n",
       "3      [time, problem, fan, noticeable, promotion, pr...   \n",
       "4      [mammootty, hint, yet, another, blockbuster, t...   \n",
       "...                                                  ...   \n",
       "19959  [sanya, malhotra, await, release, next, kathal...   \n",
       "19960  [muchawaited, telugu, film, agent, star, akhil...   \n",
       "19961  [music, composer, rahul, raj, busy, compose, s...   \n",
       "19962  [anil, sharma, back, sequel, iconic, gadar, ye...   \n",
       "19963  [actor, karthi, last, see, tamil, film, ponniy...   \n",
       "\n",
       "                                              embeddings  target  \n",
       "0      [[[0.12024946, -0.78567064, -3.5644288, -0.227...  movies  \n",
       "1      [[[-0.48352894, -0.8714409, -2.9694452, -0.066...  movies  \n",
       "2      [[[-0.7423043, -0.09902109, -3.5733092, -0.453...  movies  \n",
       "3      [[[-0.693424, 0.0857078, -3.565634, -0.3289777...  movies  \n",
       "4      [[[0.7594643, -0.7104957, -2.6859756, 0.063971...  movies  \n",
       "...                                                  ...     ...  \n",
       "19959  [[[0.17818275, -1.2513094, -3.4496045, -0.0817...  movies  \n",
       "19960  [[[0.45222053, -0.9803299, -3.006483, 0.348450...  movies  \n",
       "19961  [[[0.3546554, -0.8488461, -2.8696122, -0.22280...  movies  \n",
       "19962  [[[0.3361115, -0.86924994, -3.014597, -0.07367...  movies  \n",
       "19963  [[[1.341891, -1.0856631, -2.7355123, 0.0883205...  movies  \n",
       "\n",
       "[19964 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em13 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em13['embeddings'] = category_dfs['movies'].tokens.apply(generate_embeddings_tiny)\n",
    "em13['tokens'] = category_dfs['movies'].tokens\n",
    "em13['target'] = 'movies'\n",
    "\n",
    "em13.to_pickle('em13.pkl')\n",
    "em13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d922753",
   "metadata": {},
   "source": [
    "### Music and Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3013ffc7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[varanasi, emotional, appeal, jail, mafia, muk...</td>\n",
       "      <td>[[[-0.03909902, -0.5874695, -3.5147207, 0.0942...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[audio, c, v, kumars, thirukumaran, entertainm...</td>\n",
       "      <td>[[[0.93789816, -0.6735263, -3.3888333, -0.4636...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[first, day, shravan, maas, celebrate, devotee...</td>\n",
       "      <td>[[[-0.28844503, -1.0702789, -3.078549, 0.00616...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[music, director, raja, narayan, deb, almost, ...</td>\n",
       "      <td>[[[-0.73338974, -0.29657733, -3.4653869, -0.05...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[rapper, frank, oceans, new, album, rumour, ca...</td>\n",
       "      <td>[[[-0.45215964, 0.007470943, -2.9977071, 0.189...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19930</th>\n",
       "      <td>[increase, clarity, audio, ensure, sound, guit...</td>\n",
       "      <td>[[[0.3815494, 0.3111288, -2.922948, 0.06217082...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19931</th>\n",
       "      <td>[citroen, set, launch, c, india, market, july,...</td>\n",
       "      <td>[[[1.5777972, 1.0409086, -2.7954128, 0.5960355...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19932</th>\n",
       "      <td>[track, sohne, di, pasand, become, quite, roar...</td>\n",
       "      <td>[[[0.2326642, -1.2423159, -2.9665694, 0.069996...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19933</th>\n",
       "      <td>[state, sue, obama, administration, issue, gui...</td>\n",
       "      <td>[[[-0.7816161, 0.12276439, -3.5088573, -0.2570...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19934</th>\n",
       "      <td>[video, yearold, boy, sing, classical, song, t...</td>\n",
       "      <td>[[[-0.17296173, -1.0805869, -2.8250558, 0.0439...</td>\n",
       "      <td>music and audio</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19935 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [varanasi, emotional, appeal, jail, mafia, muk...   \n",
       "1      [audio, c, v, kumars, thirukumaran, entertainm...   \n",
       "2      [first, day, shravan, maas, celebrate, devotee...   \n",
       "3      [music, director, raja, narayan, deb, almost, ...   \n",
       "4      [rapper, frank, oceans, new, album, rumour, ca...   \n",
       "...                                                  ...   \n",
       "19930  [increase, clarity, audio, ensure, sound, guit...   \n",
       "19931  [citroen, set, launch, c, india, market, july,...   \n",
       "19932  [track, sohne, di, pasand, become, quite, roar...   \n",
       "19933  [state, sue, obama, administration, issue, gui...   \n",
       "19934  [video, yearold, boy, sing, classical, song, t...   \n",
       "\n",
       "                                              embeddings           target  \n",
       "0      [[[-0.03909902, -0.5874695, -3.5147207, 0.0942...  music and audio  \n",
       "1      [[[0.93789816, -0.6735263, -3.3888333, -0.4636...  music and audio  \n",
       "2      [[[-0.28844503, -1.0702789, -3.078549, 0.00616...  music and audio  \n",
       "3      [[[-0.73338974, -0.29657733, -3.4653869, -0.05...  music and audio  \n",
       "4      [[[-0.45215964, 0.007470943, -2.9977071, 0.189...  music and audio  \n",
       "...                                                  ...              ...  \n",
       "19930  [[[0.3815494, 0.3111288, -2.922948, 0.06217082...  music and audio  \n",
       "19931  [[[1.5777972, 1.0409086, -2.7954128, 0.5960355...  music and audio  \n",
       "19932  [[[0.2326642, -1.2423159, -2.9665694, 0.069996...  music and audio  \n",
       "19933  [[[-0.7816161, 0.12276439, -3.5088573, -0.2570...  music and audio  \n",
       "19934  [[[-0.17296173, -1.0805869, -2.8250558, 0.0439...  music and audio  \n",
       "\n",
       "[19935 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em14 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em14['embeddings'] = category_dfs['music and audio'].tokens.apply(generate_embeddings_tiny)\n",
    "em14['tokens'] = category_dfs['music and audio'].tokens\n",
    "em14['target'] = 'music and audio'\n",
    "\n",
    "em14.to_pickle('em14.pkl')\n",
    "em14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19af21a",
   "metadata": {},
   "source": [
    "### News and Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6301c22d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "em15 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em15['embeddings'] = category_dfs['news and politics'].tokens.apply(generate_embeddings_tiny)\n",
    "em15['tokens'] = category_dfs['news and politics'].tokens\n",
    "em15['target'] = 'news and politics'\n",
    "\n",
    "em15.to_pickle('em15.pkl')\n",
    "em15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aa8ad4",
   "metadata": {},
   "source": [
    "### Personal Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9990da",
   "metadata": {},
   "outputs": [],
   "source": [
    "em16 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em16['embeddings'] = category_dfs['personal finance'].tokens.apply(generate_embeddings_tiny)\n",
    "em16['tokens'] = category_dfs['personal finance'].tokens\n",
    "em16['target'] = 'personal finance'\n",
    "\n",
    "em16.to_pickle('em16.pkl')\n",
    "em16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f594211",
   "metadata": {},
   "source": [
    "### Pets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "885212a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[attracts, lot, people, curly, lock, win, smil...</td>\n",
       "      <td>[[[-0.2744318, -0.33584398, -3.4466164, -0.265...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mumbai, two, covid, year, record, low, noise,...</td>\n",
       "      <td>[[[-0.80307347, -0.14812167, -3.1064172, 0.270...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[london, ever, heard, canine, living, clothes,...</td>\n",
       "      <td>[[[-1.1969322, 0.060595892, -2.9182332, -0.179...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[hyderabad, metro, service, expand, connect, l...</td>\n",
       "      <td>[[[0.10870803, -0.108441055, -3.7882364, 0.024...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[pune, animal, activist, tuesday, accuse, civi...</td>\n",
       "      <td>[[[-1.1544473, 0.13026573, -3.5453913, 0.20309...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19925</th>\n",
       "      <td>[washington, nursing, broken, heart, brain, gi...</td>\n",
       "      <td>[[[-0.671655, -0.5662993, -3.2322612, 0.393521...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19926</th>\n",
       "      <td>[new, delhi, senior, bjp, leader, yashwant, si...</td>\n",
       "      <td>[[[-0.21502197, -0.4342892, -3.5581975, 0.1884...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19927</th>\n",
       "      <td>[delhi, zoo, official, decision, put, white, t...</td>\n",
       "      <td>[[[-0.48013178, -0.40289515, -3.0311906, -0.15...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19928</th>\n",
       "      <td>[new, delhi, staff, selection, commission, ssc...</td>\n",
       "      <td>[[[-0.2622795, 0.20005788, -3.1473475, 0.48421...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19929</th>\n",
       "      <td>[kolkata, crack, ileague, club, body, open, mo...</td>\n",
       "      <td>[[[-0.9378872, -0.17218721, -3.4694293, 0.0962...</td>\n",
       "      <td>pets</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19930 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [attracts, lot, people, curly, lock, win, smil...   \n",
       "1      [mumbai, two, covid, year, record, low, noise,...   \n",
       "2      [london, ever, heard, canine, living, clothes,...   \n",
       "3      [hyderabad, metro, service, expand, connect, l...   \n",
       "4      [pune, animal, activist, tuesday, accuse, civi...   \n",
       "...                                                  ...   \n",
       "19925  [washington, nursing, broken, heart, brain, gi...   \n",
       "19926  [new, delhi, senior, bjp, leader, yashwant, si...   \n",
       "19927  [delhi, zoo, official, decision, put, white, t...   \n",
       "19928  [new, delhi, staff, selection, commission, ssc...   \n",
       "19929  [kolkata, crack, ileague, club, body, open, mo...   \n",
       "\n",
       "                                              embeddings target  \n",
       "0      [[[-0.2744318, -0.33584398, -3.4466164, -0.265...   pets  \n",
       "1      [[[-0.80307347, -0.14812167, -3.1064172, 0.270...   pets  \n",
       "2      [[[-1.1969322, 0.060595892, -2.9182332, -0.179...   pets  \n",
       "3      [[[0.10870803, -0.108441055, -3.7882364, 0.024...   pets  \n",
       "4      [[[-1.1544473, 0.13026573, -3.5453913, 0.20309...   pets  \n",
       "...                                                  ...    ...  \n",
       "19925  [[[-0.671655, -0.5662993, -3.2322612, 0.393521...   pets  \n",
       "19926  [[[-0.21502197, -0.4342892, -3.5581975, 0.1884...   pets  \n",
       "19927  [[[-0.48013178, -0.40289515, -3.0311906, -0.15...   pets  \n",
       "19928  [[[-0.2622795, 0.20005788, -3.1473475, 0.48421...   pets  \n",
       "19929  [[[-0.9378872, -0.17218721, -3.4694293, 0.0962...   pets  \n",
       "\n",
       "[19930 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em17 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em17['embeddings'] = category_dfs['pets'].tokens.apply(generate_embeddings_tiny)\n",
    "em17['tokens'] = category_dfs['pets'].tokens\n",
    "em17['target'] = 'pets'\n",
    "\n",
    "em17.to_pickle('em17.pkl')\n",
    "em17"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5283c21",
   "metadata": {},
   "source": [
    "### Pharmaceuticals, Conditions, and Symptoms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6a0d01f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[bsd, rubiscospecific, assembly, chaperone, fo...</td>\n",
       "      <td>[[[0.4339052, 0.1840134, -3.0803385, 0.4916352...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[detection, designer, steroid, methylstenbolon...</td>\n",
       "      <td>[[[0.002714157, -0.3356166, -3.3960075, 0.8153...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[atrioventricular, conduction, disturbance, ea...</td>\n",
       "      <td>[[[-0.33025017, 0.08743937, -3.6135192, 0.4102...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[experience, concern, lesbian, gay, bisexual, ...</td>\n",
       "      <td>[[[-0.21115077, 0.22435912, -2.9130425, 0.5026...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[visual, portable, strategy, copperii, detecti...</td>\n",
       "      <td>[[[0.066294156, -0.22710928, -3.2368057, 0.480...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>[municipal, solid, waste, landfill, obvious, i...</td>\n",
       "      <td>[[[-0.42941058, -0.04120404, -3.2548974, 0.372...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>[food, environment, cause, obesity, epidemic, ...</td>\n",
       "      <td>[[[-1.1477932, 0.1254857, -3.1578948, 0.302399...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>[cue, use, black, fly, simulium, annulus, attr...</td>\n",
       "      <td>[[[0.15269783, -0.62885165, -3.0934055, 0.0397...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>[enantioselective, quenching, roomtemperature,...</td>\n",
       "      <td>[[[-0.3789984, -1.044297, -3.1685283, 0.341058...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>[decrease, regional, cerebral, blood, flow, no...</td>\n",
       "      <td>[[[0.37671322, -0.49221924, -3.213992, 0.24433...</td>\n",
       "      <td>pharmaceuticals, conditions, and symptoms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [bsd, rubiscospecific, assembly, chaperone, fo...   \n",
       "1      [detection, designer, steroid, methylstenbolon...   \n",
       "2      [atrioventricular, conduction, disturbance, ea...   \n",
       "3      [experience, concern, lesbian, gay, bisexual, ...   \n",
       "4      [visual, portable, strategy, copperii, detecti...   \n",
       "...                                                  ...   \n",
       "19995  [municipal, solid, waste, landfill, obvious, i...   \n",
       "19996  [food, environment, cause, obesity, epidemic, ...   \n",
       "19997  [cue, use, black, fly, simulium, annulus, attr...   \n",
       "19998  [enantioselective, quenching, roomtemperature,...   \n",
       "19999  [decrease, regional, cerebral, blood, flow, no...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [[[0.4339052, 0.1840134, -3.0803385, 0.4916352...   \n",
       "1      [[[0.002714157, -0.3356166, -3.3960075, 0.8153...   \n",
       "2      [[[-0.33025017, 0.08743937, -3.6135192, 0.4102...   \n",
       "3      [[[-0.21115077, 0.22435912, -2.9130425, 0.5026...   \n",
       "4      [[[0.066294156, -0.22710928, -3.2368057, 0.480...   \n",
       "...                                                  ...   \n",
       "19995  [[[-0.42941058, -0.04120404, -3.2548974, 0.372...   \n",
       "19996  [[[-1.1477932, 0.1254857, -3.1578948, 0.302399...   \n",
       "19997  [[[0.15269783, -0.62885165, -3.0934055, 0.0397...   \n",
       "19998  [[[-0.3789984, -1.044297, -3.1685283, 0.341058...   \n",
       "19999  [[[0.37671322, -0.49221924, -3.213992, 0.24433...   \n",
       "\n",
       "                                          target  \n",
       "0      pharmaceuticals, conditions, and symptoms  \n",
       "1      pharmaceuticals, conditions, and symptoms  \n",
       "2      pharmaceuticals, conditions, and symptoms  \n",
       "3      pharmaceuticals, conditions, and symptoms  \n",
       "4      pharmaceuticals, conditions, and symptoms  \n",
       "...                                          ...  \n",
       "19995  pharmaceuticals, conditions, and symptoms  \n",
       "19996  pharmaceuticals, conditions, and symptoms  \n",
       "19997  pharmaceuticals, conditions, and symptoms  \n",
       "19998  pharmaceuticals, conditions, and symptoms  \n",
       "19999  pharmaceuticals, conditions, and symptoms  \n",
       "\n",
       "[20000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em18 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em18['embeddings'] = category_dfs['pharmaceuticals, conditions, and symptoms'].tokens.apply(generate_embeddings_tiny)\n",
    "em18['tokens'] = category_dfs['pharmaceuticals, conditions, and symptoms'].tokens\n",
    "em18['target'] = 'pharmaceuticals, conditions, and symptoms'\n",
    "\n",
    "em18.to_pickle('em18.pkl')\n",
    "em18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd9f89f",
   "metadata": {},
   "source": [
    "### Real Estate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2dfdcf73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[every, goan, look, forward, budget, hope, anx...</td>\n",
       "      <td>[[[-0.14088474, 0.90604264, -3.4344857, 0.2458...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[kanpur, dwarka, indore, pushkar, current, fin...</td>\n",
       "      <td>[[[0.46130678, 0.5565112, -3.2509441, 0.319476...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[story, originally, appear, jan, mumbai, ajay,...</td>\n",
       "      <td>[[[0.73447603, -0.4446726, -2.9824378, -0.0964...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[palghar, real, estate, agent, adjoin, thane, ...</td>\n",
       "      <td>[[[-0.050025187, 0.24896339, -3.6244338, -0.34...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[visakhapatnam, ap, build, construction, worke...</td>\n",
       "      <td>[[[-0.1500141, 1.0880865, -3.7125459, -0.37606...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19899</th>\n",
       "      <td>[great, noida, real, estate, project, resident...</td>\n",
       "      <td>[[[0.4951115, 0.693795, -3.8600295, 0.38007003...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19900</th>\n",
       "      <td>[idbi, bank, make, successful, transformation,...</td>\n",
       "      <td>[[[-0.11541903, 0.7290096, -3.382159, 0.233584...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19901</th>\n",
       "      <td>[kolkata, sleuth, probe, trinetra, muddle, try...</td>\n",
       "      <td>[[[0.10376262, 0.46605602, -3.1463823, -0.1181...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19902</th>\n",
       "      <td>[jaipur, transition, new, order, regime, usual...</td>\n",
       "      <td>[[[0.09268921, 0.8196367, -3.2968647, 0.079396...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>[new, delhi, jan, housing, sale, drop, per, ce...</td>\n",
       "      <td>[[[0.04278697, -0.58573806, -3.311496, -0.0147...</td>\n",
       "      <td>real estate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19904 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [every, goan, look, forward, budget, hope, anx...   \n",
       "1      [kanpur, dwarka, indore, pushkar, current, fin...   \n",
       "2      [story, originally, appear, jan, mumbai, ajay,...   \n",
       "3      [palghar, real, estate, agent, adjoin, thane, ...   \n",
       "4      [visakhapatnam, ap, build, construction, worke...   \n",
       "...                                                  ...   \n",
       "19899  [great, noida, real, estate, project, resident...   \n",
       "19900  [idbi, bank, make, successful, transformation,...   \n",
       "19901  [kolkata, sleuth, probe, trinetra, muddle, try...   \n",
       "19902  [jaipur, transition, new, order, regime, usual...   \n",
       "19903  [new, delhi, jan, housing, sale, drop, per, ce...   \n",
       "\n",
       "                                              embeddings       target  \n",
       "0      [[[-0.14088474, 0.90604264, -3.4344857, 0.2458...  real estate  \n",
       "1      [[[0.46130678, 0.5565112, -3.2509441, 0.319476...  real estate  \n",
       "2      [[[0.73447603, -0.4446726, -2.9824378, -0.0964...  real estate  \n",
       "3      [[[-0.050025187, 0.24896339, -3.6244338, -0.34...  real estate  \n",
       "4      [[[-0.1500141, 1.0880865, -3.7125459, -0.37606...  real estate  \n",
       "...                                                  ...          ...  \n",
       "19899  [[[0.4951115, 0.693795, -3.8600295, 0.38007003...  real estate  \n",
       "19900  [[[-0.11541903, 0.7290096, -3.382159, 0.233584...  real estate  \n",
       "19901  [[[0.10376262, 0.46605602, -3.1463823, -0.1181...  real estate  \n",
       "19902  [[[0.09268921, 0.8196367, -3.2968647, 0.079396...  real estate  \n",
       "19903  [[[0.04278697, -0.58573806, -3.311496, -0.0147...  real estate  \n",
       "\n",
       "[19904 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em19= pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em19['embeddings'] = category_dfs['real estate'].tokens.apply(generate_embeddings_tiny)\n",
    "em19['tokens'] = category_dfs['real estate'].tokens\n",
    "em19['target'] = 'real estate'\n",
    "\n",
    "em19.to_pickle('em19.pkl')\n",
    "em19"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a177d58f",
   "metadata": {},
   "source": [
    "### Shopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "181fbd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[nagpur, grow, discontent, among, shopkeeper, ...</td>\n",
       "      <td>[[[-0.2616686, -0.31717837, -3.7391768, 0.4168...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[c, provide, easy, way, new, upcoming, store, ...</td>\n",
       "      <td>[[[-0.16900353, 0.56783587, -2.431405, 0.65915...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[agra, week, daylight, robbery, r, lakh, worth...</td>\n",
       "      <td>[[[0.14632499, -0.026408065, -3.2015102, -0.10...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thane, wine, shop, employee, attack, robbed, ...</td>\n",
       "      <td>[[[-0.3083456, 0.580503, -3.067747, -0.3861562...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[jaipur, police, team, investigate, acid, atta...</td>\n",
       "      <td>[[[-0.050641373, 0.30032533, -3.6919365, -0.04...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19921</th>\n",
       "      <td>[kolkata, senco, gold, diamond, one, lead, jew...</td>\n",
       "      <td>[[[-0.14701563, 0.62221766, -2.9163213, 0.5378...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19922</th>\n",
       "      <td>[new, delhi, delhi, government, tuesday, bid, ...</td>\n",
       "      <td>[[[-0.18179518, -0.10970786, -2.953076, 0.1505...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19923</th>\n",
       "      <td>[claw, back, cautious, expansion, cloud, kitch...</td>\n",
       "      <td>[[[-0.33542868, -0.08832374, -3.284313, 0.2069...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19924</th>\n",
       "      <td>[begin, hadnt, define, role, well, thing, like...</td>\n",
       "      <td>[[[-0.4348865, -0.011288058, -3.0847151, 0.338...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19925</th>\n",
       "      <td>[million, australian, close, half, population,...</td>\n",
       "      <td>[[[-0.89149606, 0.20455207, -3.7661886, -0.164...</td>\n",
       "      <td>shopping</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19926 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [nagpur, grow, discontent, among, shopkeeper, ...   \n",
       "1      [c, provide, easy, way, new, upcoming, store, ...   \n",
       "2      [agra, week, daylight, robbery, r, lakh, worth...   \n",
       "3      [thane, wine, shop, employee, attack, robbed, ...   \n",
       "4      [jaipur, police, team, investigate, acid, atta...   \n",
       "...                                                  ...   \n",
       "19921  [kolkata, senco, gold, diamond, one, lead, jew...   \n",
       "19922  [new, delhi, delhi, government, tuesday, bid, ...   \n",
       "19923  [claw, back, cautious, expansion, cloud, kitch...   \n",
       "19924  [begin, hadnt, define, role, well, thing, like...   \n",
       "19925  [million, australian, close, half, population,...   \n",
       "\n",
       "                                              embeddings    target  \n",
       "0      [[[-0.2616686, -0.31717837, -3.7391768, 0.4168...  shopping  \n",
       "1      [[[-0.16900353, 0.56783587, -2.431405, 0.65915...  shopping  \n",
       "2      [[[0.14632499, -0.026408065, -3.2015102, -0.10...  shopping  \n",
       "3      [[[-0.3083456, 0.580503, -3.067747, -0.3861562...  shopping  \n",
       "4      [[[-0.050641373, 0.30032533, -3.6919365, -0.04...  shopping  \n",
       "...                                                  ...       ...  \n",
       "19921  [[[-0.14701563, 0.62221766, -2.9163213, 0.5378...  shopping  \n",
       "19922  [[[-0.18179518, -0.10970786, -2.953076, 0.1505...  shopping  \n",
       "19923  [[[-0.33542868, -0.08832374, -3.284313, 0.2069...  shopping  \n",
       "19924  [[[-0.4348865, -0.011288058, -3.0847151, 0.338...  shopping  \n",
       "19925  [[[-0.89149606, 0.20455207, -3.7661886, -0.164...  shopping  \n",
       "\n",
       "[19926 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em20= pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em20['embeddings'] = category_dfs['shopping'].tokens.apply(generate_embeddings_tiny)\n",
    "em20['tokens'] = category_dfs['shopping'].tokens\n",
    "em20['target'] = 'shopping'\n",
    "\n",
    "em20.to_pickle('em20.pkl')\n",
    "em20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bba23155",
   "metadata": {},
   "source": [
    "### Sports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "390bdfd0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[like, guy, senior, candidate, fall, regular, ...</td>\n",
       "      <td>[[[-1.2214168, -0.6665672, -2.591603, 0.636053...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[chandigarh, city, still, devoid, velodrome, b...</td>\n",
       "      <td>[[[0.044711635, 0.3341138, -3.5448737, 0.26063...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[bagger, sport, team, sport, superstore, bagge...</td>\n",
       "      <td>[[[0.111487724, 1.2707283, -1.8765707, 0.49902...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[birmingham, one, worst, performances, recent,...</td>\n",
       "      <td>[[[-0.68588865, -0.56535804, -2.893442, 0.1722...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[mohali, day, shiromani, akali, dal, sad, lead...</td>\n",
       "      <td>[[[0.65082806, 0.7645988, -3.227178, -0.007076...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19942</th>\n",
       "      <td>[kolkata, former, olympian, sibling, archer, d...</td>\n",
       "      <td>[[[-0.019192204, 0.6518846, -3.791482, 0.14346...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19943</th>\n",
       "      <td>[margao, brace, subhash, singh, help, pune, fc...</td>\n",
       "      <td>[[[-0.50884914, -0.7743169, -2.9629924, -0.054...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19944</th>\n",
       "      <td>[opposite, direction, saddle, mark, could, kee...</td>\n",
       "      <td>[[[-0.77383345, -0.7328107, -3.2686257, 0.2386...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19945</th>\n",
       "      <td>[hyderabad, kvr, hemanth, kumar, bag, allindia...</td>\n",
       "      <td>[[[-0.4301642, -0.49534556, -3.2820365, -0.262...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>[vadodara, national, youth, league, football, ...</td>\n",
       "      <td>[[[-0.50730336, -0.87745935, -2.739925, 0.2083...</td>\n",
       "      <td>sports</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19947 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [like, guy, senior, candidate, fall, regular, ...   \n",
       "1      [chandigarh, city, still, devoid, velodrome, b...   \n",
       "2      [bagger, sport, team, sport, superstore, bagge...   \n",
       "3      [birmingham, one, worst, performances, recent,...   \n",
       "4      [mohali, day, shiromani, akali, dal, sad, lead...   \n",
       "...                                                  ...   \n",
       "19942  [kolkata, former, olympian, sibling, archer, d...   \n",
       "19943  [margao, brace, subhash, singh, help, pune, fc...   \n",
       "19944  [opposite, direction, saddle, mark, could, kee...   \n",
       "19945  [hyderabad, kvr, hemanth, kumar, bag, allindia...   \n",
       "19946  [vadodara, national, youth, league, football, ...   \n",
       "\n",
       "                                              embeddings  target  \n",
       "0      [[[-1.2214168, -0.6665672, -2.591603, 0.636053...  sports  \n",
       "1      [[[0.044711635, 0.3341138, -3.5448737, 0.26063...  sports  \n",
       "2      [[[0.111487724, 1.2707283, -1.8765707, 0.49902...  sports  \n",
       "3      [[[-0.68588865, -0.56535804, -2.893442, 0.1722...  sports  \n",
       "4      [[[0.65082806, 0.7645988, -3.227178, -0.007076...  sports  \n",
       "...                                                  ...     ...  \n",
       "19942  [[[-0.019192204, 0.6518846, -3.791482, 0.14346...  sports  \n",
       "19943  [[[-0.50884914, -0.7743169, -2.9629924, -0.054...  sports  \n",
       "19944  [[[-0.77383345, -0.7328107, -3.2686257, 0.2386...  sports  \n",
       "19945  [[[-0.4301642, -0.49534556, -3.2820365, -0.262...  sports  \n",
       "19946  [[[-0.50730336, -0.87745935, -2.739925, 0.2083...  sports  \n",
       "\n",
       "[19947 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em21 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em21['embeddings'] = category_dfs['sports'].tokens.apply(generate_embeddings_tiny)\n",
    "em21['tokens'] = category_dfs['sports'].tokens\n",
    "em21['target'] = 'sports'\n",
    "\n",
    "em21.to_pickle('em21.pkl')\n",
    "em21"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fb40ff",
   "metadata": {},
   "source": [
    "### Style and Fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "182d2e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[new, delhi, reliance, brand, part, mukesh, am...</td>\n",
       "      <td>[[[1.1418712, 0.5607771, -3.0414205, 0.4445514...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[heady, cocktail, style, popup, shop, music, m...</td>\n",
       "      <td>[[[-0.35711214, -0.53387845, -2.882807, -0.473...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[day, ago, urfi, javed, got, heat, argument, s...</td>\n",
       "      <td>[[[-0.74995863, -0.32927155, -3.1973088, -0.01...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bhubaneswar, three, student, national, instit...</td>\n",
       "      <td>[[[-0.48081103, 0.43996307, -3.8694308, -0.097...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[spread, three, day, jury, meet, thetimes, unl...</td>\n",
       "      <td>[[[-0.28595927, -0.28531933, -2.83979, 0.23370...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19946</th>\n",
       "      <td>[amazon, sale, present, excite, opportunity, g...</td>\n",
       "      <td>[[[0.26187396, 0.2943267, -2.282716, 0.4194376...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19947</th>\n",
       "      <td>[deepika, padukone, sport, black, mermaid, dre...</td>\n",
       "      <td>[[[0.18507218, -0.2549331, -2.7090151, 0.16098...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19948</th>\n",
       "      <td>[septum, pierce, moment, sun, celebrity, like,...</td>\n",
       "      <td>[[[-0.1945121, -0.30619642, -2.3851593, -0.111...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19949</th>\n",
       "      <td>[new, delhi, australian, designer, create, sti...</td>\n",
       "      <td>[[[0.26867902, 0.36772954, -2.5051053, 0.27615...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19950</th>\n",
       "      <td>[prone, continuously, hence, occupational, haz...</td>\n",
       "      <td>[[[-0.38230598, 0.028394084, -3.5366278, 0.042...</td>\n",
       "      <td>style and fashion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19951 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [new, delhi, reliance, brand, part, mukesh, am...   \n",
       "1      [heady, cocktail, style, popup, shop, music, m...   \n",
       "2      [day, ago, urfi, javed, got, heat, argument, s...   \n",
       "3      [bhubaneswar, three, student, national, instit...   \n",
       "4      [spread, three, day, jury, meet, thetimes, unl...   \n",
       "...                                                  ...   \n",
       "19946  [amazon, sale, present, excite, opportunity, g...   \n",
       "19947  [deepika, padukone, sport, black, mermaid, dre...   \n",
       "19948  [septum, pierce, moment, sun, celebrity, like,...   \n",
       "19949  [new, delhi, australian, designer, create, sti...   \n",
       "19950  [prone, continuously, hence, occupational, haz...   \n",
       "\n",
       "                                              embeddings             target  \n",
       "0      [[[1.1418712, 0.5607771, -3.0414205, 0.4445514...  style and fashion  \n",
       "1      [[[-0.35711214, -0.53387845, -2.882807, -0.473...  style and fashion  \n",
       "2      [[[-0.74995863, -0.32927155, -3.1973088, -0.01...  style and fashion  \n",
       "3      [[[-0.48081103, 0.43996307, -3.8694308, -0.097...  style and fashion  \n",
       "4      [[[-0.28595927, -0.28531933, -2.83979, 0.23370...  style and fashion  \n",
       "...                                                  ...                ...  \n",
       "19946  [[[0.26187396, 0.2943267, -2.282716, 0.4194376...  style and fashion  \n",
       "19947  [[[0.18507218, -0.2549331, -2.7090151, 0.16098...  style and fashion  \n",
       "19948  [[[-0.1945121, -0.30619642, -2.3851593, -0.111...  style and fashion  \n",
       "19949  [[[0.26867902, 0.36772954, -2.5051053, 0.27615...  style and fashion  \n",
       "19950  [[[-0.38230598, 0.028394084, -3.5366278, 0.042...  style and fashion  \n",
       "\n",
       "[19951 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em22 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em22['embeddings'] = category_dfs['style and fashion'].tokens.apply(generate_embeddings_tiny)\n",
    "em22['tokens'] = category_dfs['style and fashion'].tokens\n",
    "em22['target'] = 'style and fashion'\n",
    "\n",
    "em22.to_pickle('em22.pkl')\n",
    "em22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851f97ec",
   "metadata": {},
   "source": [
    "### Technology and Computing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5d035b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[police, india, symbol, government, visible, s...</td>\n",
       "      <td>[[[0.22332993, 0.6552329, -3.1005552, 0.094203...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[believe, everyone, learn, code, skill, cod, d...</td>\n",
       "      <td>[[[-1.0407336, -0.5918205, -2.4913363, -0.2869...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[br, br, pantaloon, retail, r, attract, buy, i...</td>\n",
       "      <td>[[[0.75906384, -0.090520784, -2.7929275, -0.20...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[also, keep, intact, shallow, back, sit, chair...</td>\n",
       "      <td>[[[-0.54617494, 0.52954286, -2.9020262, 0.1468...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[stockholm, quantum, physic, invisibility, clo...</td>\n",
       "      <td>[[[-0.4427388, -0.8366893, -2.9597554, 0.64090...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19859</th>\n",
       "      <td>[visakhapatnam, artificial, intelligence, mach...</td>\n",
       "      <td>[[[0.34615126, 0.7037862, -3.2001855, 0.428937...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19860</th>\n",
       "      <td>[kochi, anfil, shajo, thirdyear, student, toc,...</td>\n",
       "      <td>[[[-0.30385295, 0.5034431, -3.8514528, -0.0042...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19861</th>\n",
       "      <td>[recent, decision, us, appellate, court, refer...</td>\n",
       "      <td>[[[-0.34242538, 0.99992347, -3.1940587, 0.3381...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19862</th>\n",
       "      <td>[kochi, two, week, edusap, intelligent, studen...</td>\n",
       "      <td>[[[0.0716222, 0.25664034, -3.0896528, 0.556417...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19863</th>\n",
       "      <td>[bengaluru, yearold, assistant, professor, rep...</td>\n",
       "      <td>[[[0.19213152, 0.25887248, -3.4770446, 0.22653...</td>\n",
       "      <td>technology and computing</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19864 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [police, india, symbol, government, visible, s...   \n",
       "1      [believe, everyone, learn, code, skill, cod, d...   \n",
       "2      [br, br, pantaloon, retail, r, attract, buy, i...   \n",
       "3      [also, keep, intact, shallow, back, sit, chair...   \n",
       "4      [stockholm, quantum, physic, invisibility, clo...   \n",
       "...                                                  ...   \n",
       "19859  [visakhapatnam, artificial, intelligence, mach...   \n",
       "19860  [kochi, anfil, shajo, thirdyear, student, toc,...   \n",
       "19861  [recent, decision, us, appellate, court, refer...   \n",
       "19862  [kochi, two, week, edusap, intelligent, studen...   \n",
       "19863  [bengaluru, yearold, assistant, professor, rep...   \n",
       "\n",
       "                                              embeddings  \\\n",
       "0      [[[0.22332993, 0.6552329, -3.1005552, 0.094203...   \n",
       "1      [[[-1.0407336, -0.5918205, -2.4913363, -0.2869...   \n",
       "2      [[[0.75906384, -0.090520784, -2.7929275, -0.20...   \n",
       "3      [[[-0.54617494, 0.52954286, -2.9020262, 0.1468...   \n",
       "4      [[[-0.4427388, -0.8366893, -2.9597554, 0.64090...   \n",
       "...                                                  ...   \n",
       "19859  [[[0.34615126, 0.7037862, -3.2001855, 0.428937...   \n",
       "19860  [[[-0.30385295, 0.5034431, -3.8514528, -0.0042...   \n",
       "19861  [[[-0.34242538, 0.99992347, -3.1940587, 0.3381...   \n",
       "19862  [[[0.0716222, 0.25664034, -3.0896528, 0.556417...   \n",
       "19863  [[[0.19213152, 0.25887248, -3.4770446, 0.22653...   \n",
       "\n",
       "                         target  \n",
       "0      technology and computing  \n",
       "1      technology and computing  \n",
       "2      technology and computing  \n",
       "3      technology and computing  \n",
       "4      technology and computing  \n",
       "...                         ...  \n",
       "19859  technology and computing  \n",
       "19860  technology and computing  \n",
       "19861  technology and computing  \n",
       "19862  technology and computing  \n",
       "19863  technology and computing  \n",
       "\n",
       "[19864 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em23 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em23['embeddings'] = category_dfs['technology and computing'].tokens.apply(generate_embeddings_tiny)\n",
    "em23['tokens'] = category_dfs['technology and computing'].tokens\n",
    "em23['target'] = 'technology and computing'\n",
    "\n",
    "em23.to_pickle('em23.pkl')\n",
    "em23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163cfaf2",
   "metadata": {},
   "source": [
    "### Television"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b87b7fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[ahmedabad, tv, burn, shortcircuit, cable, con...</td>\n",
       "      <td>[[[1.2417403, 0.12508991, -3.090032, 0.0969250...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[mumbai, tv, credit, service, financial, socie...</td>\n",
       "      <td>[[[0.8603846, 0.6418869, -3.0246942, 0.3524107...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[google, set, motion, competitor, amazon, blas...</td>\n",
       "      <td>[[[1.2471682, -0.32991382, -1.8462965, 0.36308...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[sensation, mollywood, megastar, mammootty, ce...</td>\n",
       "      <td>[[[0.4589956, -1.5233244, -2.651807, -0.047192...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[priyanka, naidu, madhubabu, celebrate, seven,...</td>\n",
       "      <td>[[[0.09309777, -1.3201134, -3.6223571, 0.04883...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19960</th>\n",
       "      <td>[india, electricity, fluctuation, trip, common...</td>\n",
       "      <td>[[[0.7898882, 0.5650754, -2.8760245, 0.5417888...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19961</th>\n",
       "      <td>[new, delhi, planning, buying, scooter, rs, di...</td>\n",
       "      <td>[[[0.7273347, 1.5811505, -3.0170944, 0.4659032...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19962</th>\n",
       "      <td>[malayalam, tv, long, list, reality, show, boa...</td>\n",
       "      <td>[[[-0.08145107, -1.7926432, -2.5853202, -0.063...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19963</th>\n",
       "      <td>[new, mythological, tv, show, dnyaneshwar, mau...</td>\n",
       "      <td>[[[0.29283282, -1.5512469, -3.119585, -0.05085...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19964</th>\n",
       "      <td>[pune, veteran, stage, film, television, actor...</td>\n",
       "      <td>[[[0.7045674, -1.4877698, -2.8049872, -0.06457...</td>\n",
       "      <td>television</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19965 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tokens  \\\n",
       "0      [ahmedabad, tv, burn, shortcircuit, cable, con...   \n",
       "1      [mumbai, tv, credit, service, financial, socie...   \n",
       "2      [google, set, motion, competitor, amazon, blas...   \n",
       "3      [sensation, mollywood, megastar, mammootty, ce...   \n",
       "4      [priyanka, naidu, madhubabu, celebrate, seven,...   \n",
       "...                                                  ...   \n",
       "19960  [india, electricity, fluctuation, trip, common...   \n",
       "19961  [new, delhi, planning, buying, scooter, rs, di...   \n",
       "19962  [malayalam, tv, long, list, reality, show, boa...   \n",
       "19963  [new, mythological, tv, show, dnyaneshwar, mau...   \n",
       "19964  [pune, veteran, stage, film, television, actor...   \n",
       "\n",
       "                                              embeddings      target  \n",
       "0      [[[1.2417403, 0.12508991, -3.090032, 0.0969250...  television  \n",
       "1      [[[0.8603846, 0.6418869, -3.0246942, 0.3524107...  television  \n",
       "2      [[[1.2471682, -0.32991382, -1.8462965, 0.36308...  television  \n",
       "3      [[[0.4589956, -1.5233244, -2.651807, -0.047192...  television  \n",
       "4      [[[0.09309777, -1.3201134, -3.6223571, 0.04883...  television  \n",
       "...                                                  ...         ...  \n",
       "19960  [[[0.7898882, 0.5650754, -2.8760245, 0.5417888...  television  \n",
       "19961  [[[0.7273347, 1.5811505, -3.0170944, 0.4659032...  television  \n",
       "19962  [[[-0.08145107, -1.7926432, -2.5853202, -0.063...  television  \n",
       "19963  [[[0.29283282, -1.5512469, -3.119585, -0.05085...  television  \n",
       "19964  [[[0.7045674, -1.4877698, -2.8049872, -0.06457...  television  \n",
       "\n",
       "[19965 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "em24 = pd.DataFrame(columns = ['tokens', 'embeddings', 'target'])\n",
    "em24['embeddings'] = category_dfs['television'].tokens.apply(generate_embeddings_tiny)\n",
    "em24['tokens'] = category_dfs['television'].tokens\n",
    "em24['target'] = 'television'\n",
    "\n",
    "em24.to_pickle('em24.pkl')\n",
    "em24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026263cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
